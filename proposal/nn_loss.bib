
@inproceedings{NEURIPS2018_a41b3bb3,
 author = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Visualizing the Loss Landscape of Neural Nets},
 url = {https://proceedings.neurips.cc/paper/2018/file/a41b3bb3e6b050b6c9067c67f663b915-Paper.pdf},
 volume = {31},
 year = {2018}
}

@article{hochreiter1997flat,
  title={Flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={1},
  pages={1--42},
  year={1997},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}


@InProceedings{pmlr-v137-huang20a,
  title = 	 {Understanding Generalization Through Visualizations},
  author =       {Huang, W. Ronny and Emam, Zeyad and Goldblum, Micah and Fowl, Liam and Terry, Justin K. and Huang, Furong and Goldstein, Tom},
  booktitle = 	 {Proceedings on "I Can't Believe It's Not Better!" at NeurIPS Workshops},
  pages = 	 {87--97},
  year = 	 {2020},
  editor = 	 {Zosa Forde, Jessica and Ruiz, Francisco and Pradier, Melanie F. and Schein, Aaron},
  volume = 	 {137},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v137/huang20a/huang20a.pdf},
  url = 	 {https://proceedings.mlr.press/v137/huang20a.html},
  abstract = 	 {The power of neural networks lies in their ability to generalize to unseen data, yet the underlying reasons for this phenomenon remain elusive. Numerous rigorous attempts have been made to explain generalization, but available bounds are still quite loose, and analysis does not always lead to true understanding. The goal of this work is to make generalization more intuitive. Using visualization methods, we discuss the mystery of generalization, the geometry of loss landscapes, and how the curse (or, rather, the blessing) of dimensionality causes optimizers to settle into minima that generalize well.}
}

@article{linse2022walk,
  title={A walk in the black-box: 3D visualization of large neural networks in virtual reality},
  author={Linse, Christoph and Alshazly, Hammam and Martinetz, Thomas},
  journal={Neural Computing and Applications},
  pages={1--16},
  year={2022},
  publisher={Springer}
}

@misc{actor2020,
  doi = {10.48550/ARXIV.2009.02391},
  url = {https://arxiv.org/abs/2009.02391},
  author = {Bekci, Recep Yusuf and Gümüş, Mehmet},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Visualizing the Loss Landscape of Actor Critic Methods with Applications in Inventory Optimization},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{plaat2022deep,
  title={Deep Reinforcement Learning},
  author={Plaat, Aske},
  journal={arXiv preprint arXiv:2201.02135},
  year={2022}
}
