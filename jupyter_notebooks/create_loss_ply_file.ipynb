{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f89f006d",
      "metadata": {
        "id": "f89f006d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9b154db",
      "metadata": {
        "id": "f9b154db"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    \n",
        "    training_data = torchvision.datasets.CIFAR10(root = 'data',\n",
        "                                               train = True,\n",
        "                                               transform = transform,\n",
        "                                               download = True)\n",
        "\n",
        "    testing_data = torchvision.datasets.CIFAR10(root = 'data',\n",
        "                                              train = False,\n",
        "                                              transform = transform,\n",
        "                                              download=True)\n",
        "    \n",
        "    return training_data, testing_data\n",
        "\n",
        "def get_loaders(training_data, testing_data, batch_size):\n",
        "    training_loader = torch.utils.data.DataLoader(dataset = training_data,\n",
        "                                                  batch_size = batch_size,\n",
        "                                                  shuffle = True)\n",
        "\n",
        "    testing_loader = torch.utils.data.DataLoader(dataset = testing_data,\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 shuffle = True)\n",
        "    \n",
        "    return training_loader, testing_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d6de4c",
      "metadata": {
        "id": "00d6de4c"
      },
      "outputs": [],
      "source": [
        "def train(model, training_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    num_correct = 0\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # TODO: remove this, just here to cut down on running time\n",
        "        if(i == 50):\n",
        "            break\n",
        "        print(\"Training i:\" + str(i))\n",
        "        data, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, labels)\n",
        "        running_loss += loss.item()\n",
        "        _, predictions = torch.max(output.data, 1)\n",
        "        num_correct += (predictions == labels).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    # TODO: remove this, just here to cut down on running time\n",
        "    loss = running_loss/(10*50)\n",
        "    #loss = running_loss/len(training_loader.dataset)\n",
        "    accuracy = num_correct/ (10*50)\n",
        "    #accuracy = num_correct/len(training_loader.dataset)\n",
        "    print(f'Train Loss: {loss:.4f}, Train Acc: {accuracy:.2f}')\n",
        "    \n",
        "    return loss, accuracy\n",
        "\n",
        "def test(model, testing_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    num_correct = 0\n",
        "    for i, data in enumerate(testing_loader):\n",
        "        # TODO: remove this, just here to cut down on running time\n",
        "        if(i == 10):\n",
        "            break\n",
        "        print(\"Testing i:\" + str(i))\n",
        "        data, labels = data[0].to(device), data[1].to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, labels)\n",
        "        running_loss += loss.item()\n",
        "        _, predictions = torch.max(output.data, 1)\n",
        "        num_correct += (predictions == labels).sum().item()\n",
        "    \n",
        "    # TODO: remove this, just here to cut down on running time\n",
        "    loss = running_loss/(10*10)\n",
        "    #loss = running_loss/len(testing_loader.dataset)\n",
        "    accuracy = num_correct/(10*10)\n",
        "    #accuracy = num_correct/len(testing_loader.dataset)\n",
        "    print(f'Test Loss: {loss:.4f}, Test Acc: {accuracy:.2f}')\n",
        "    \n",
        "    return loss, accuracy\n",
        "\n",
        "def pre_train_and_test(model, training_loader, testing_loader, criterion, optimizer):\n",
        "    training_historical_loss, training_historical_accuracy = [], []\n",
        "    testing_historical_loss, testing_historical_accuracy = [], []\n",
        "\n",
        "    # TODO: make larger,\n",
        "    for epoch in range(1):\n",
        "        print(\"epoch: \" + str(epoch))\n",
        "        training_loss, training_accuracy = train(model, training_loader, criterion, optimizer)\n",
        "        testing_loss, testing_accuracy = test(model, testing_loader, criterion)\n",
        "        training_historical_loss.append(training_loss)\n",
        "        training_historical_accuracy.append(training_accuracy)\n",
        "        testing_historical_loss.append(testing_loss)\n",
        "        testing_historical_loss.append(testing_accuracy)\n",
        "        \n",
        "    return  training_historical_loss, testing_historical_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "384b1ba2",
      "metadata": {
        "id": "384b1ba2"
      },
      "outputs": [],
      "source": [
        "def get_weights(model):\n",
        "    return [param.data for param in model.parameters()]\n",
        "\n",
        "def get_random_directions(weights, device):\n",
        "    return [torch.randn(w.size()).to(device) for w in weights]\n",
        "\n",
        "def normalize_directions(directions, weights):\n",
        "    for d, w in zip(directions, weights):\n",
        "        d.mul_(w.norm()/(d.norm() + 1e-10))\n",
        "\n",
        "def tensorlist_to_tensor(weights):\n",
        "    return torch.cat([w.cpu().view(w.cpu().numel()) if w.dim() > 1 else torch.FloatTensor(w.cpu()) for w in weights])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57d94b68",
      "metadata": {
        "id": "57d94b68"
      },
      "outputs": [],
      "source": [
        "def plot_figure(X, Y, Z, title):\n",
        "    fig = plt.figure(figsize=(10,7.5))\n",
        "    ax0 = fig.add_subplot(projection='3d' )\n",
        "\n",
        "    ax0.view_init(elev=30, azim=-20)\n",
        "    ax0.set_xlabel('X', labelpad=9)\n",
        "    ax0.set_ylabel('Y', labelpad=-5)\n",
        "    ax0.set_zlabel(\"Loss\", labelpad=-30)\n",
        "    ax0.tick_params(axis='x', pad=5, which='major')\n",
        "    ax0.tick_params(axis='y', pad=-5, which='major')\n",
        "    ax0.tick_params(axis='z', pad=5, which='major')\n",
        "    ax0.set_title(title, y=0.85)\n",
        "    ax0.plot_surface(X, Y, Z, cmap='terrain', antialiased=True, cstride=1, rstride=1, alpha=0.75)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93efe758",
      "metadata": {
        "id": "93efe758"
      },
      "outputs": [],
      "source": [
        "def get_random_direction_losses(model, testing_loader, criterion, device):\n",
        "    \n",
        "    weights = get_weights(model)\n",
        "\n",
        "    random_x_directions = get_random_directions(weights, device);\n",
        "    random_y_directions = get_random_directions(weights, device);\n",
        "\n",
        "    normalize_directions(random_x_directions, weights);\n",
        "    normalize_directions(random_y_directions, weights);\n",
        "\n",
        "    x_coordinates = np.arange(-0.1, 0.125, 0.025)   \n",
        "    y_coordinates = np.arange(-0.1, 0.125, 0.025)  \n",
        "    X, Y = np.meshgrid(x_coordinates, y_coordinates)\n",
        "    Z = np.zeros((x_coordinates.size, y_coordinates.size))\n",
        "\n",
        "    for y_index, y in enumerate(y_coordinates):\n",
        "        for x_index, x in enumerate(x_coordinates):\n",
        "        \n",
        "            print(\"X: \" + str(x))\n",
        "            print(\"Y: \" + str(y))\n",
        "        \n",
        "            updated_x_directions = [direction * x for direction in random_x_directions]\n",
        "            updated_y_directions = [direction * y for direction in random_y_directions]\n",
        "            delta = [sum(direction) for direction in zip(updated_x_directions, updated_y_directions)]\n",
        "            old_weights = copy.deepcopy(get_weights(model))\n",
        "        \n",
        "            for (p, w, d) in zip(model.parameters(), old_weights, delta):\n",
        "                p.data = w + torch.Tensor(d).type(type(w)).to(device)\n",
        "            \n",
        "            testing_loss, testing_accuracy = test(model, testing_loader, criterion)\n",
        "            Z[y_index][x_index] = testing_loss\n",
        "        \n",
        "            for (p, w) in zip(model.parameters(), old_weights):\n",
        "                p.data = w\n",
        "                \n",
        "    return X, Y, Z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pca_to_directions(pca, weights):\n",
        "      directions = copy.deepcopy(weights)\n",
        "      idx = 0\n",
        "      for w in directions:\n",
        "          w.copy_(torch.tensor(pca[idx:idx + w.numel()]).view(w.size()))\n",
        "          idx += w.numel()\n",
        "      return directions"
      ],
      "metadata": {
        "id": "eXgZy92nh0jl"
      },
      "id": "eXgZy92nh0jl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pca_losses(model, training_loader, testing_loader, criterion, device, optimizer):\n",
        "\n",
        "    weights = []\n",
        "    for epoch in range(2):\n",
        "        train(model, training_loader, criterion, optimizer)\n",
        "        training_weights = get_weights(model)\n",
        "        weights.append(tensorlist_to_tensor(training_weights).numpy())\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    pca.fit(np.array(weights))\n",
        "    pca1 = np.array(pca.components_[0])\n",
        "    pca2 = np.array(pca.components_[1])\n",
        "\n",
        "    #TODO: Figure out what exactly the second argument here should be\n",
        "    #pca_x_directions = pca_to_directions(pca1, )\n",
        "    #pca_y_directions = pca_to_directions(pca2, )\n",
        "\n",
        "    x_coordinates = np.arange(-0.1, 0.125, 0.025)   \n",
        "    y_coordinates = np.arange(-0.1, 0.125, 0.025)  \n",
        "\n",
        "    X, Y = np.meshgrid(x_coordinates, y_coordinates)\n",
        "    Z = np.zeros((x_coordinates.size, y_coordinates.size))\n",
        "\n",
        "    for y_index, y in enumerate(y_coordinates):\n",
        "        for x_index, x in enumerate(x_coordinates):\n",
        "        \n",
        "            print(\"X: \" + str(x))\n",
        "            print(\"Y: \" + str(y))\n",
        "\n",
        "    return X, Y, Z"
      ],
      "metadata": {
        "id": "i7oUG_JWF-06"
      },
      "id": "i7oUG_JWF-06",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0309910a",
      "metadata": {
        "id": "0309910a"
      },
      "outputs": [],
      "source": [
        "def create_random_direction_loss_landscape(model, testing_loader, criterion, device, graph_title):\n",
        "    X, Y, Z = get_random_direction_losses(model, testing_loader, criterion, device)\n",
        "    plot_figure(X, Y, Z, graph_title)\n",
        "\n",
        "def create_pca_loss_landscape(model, training_loader, testing_loader, criterion, device, optimizer, graph_title):\n",
        "    X, Y, Z = get_pca_losses(model, training_loader, testing_loader, criterion, device, optimizer)\n",
        "    plot_figure(X, Y, Z, graph_title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fc3d24a",
      "metadata": {
        "id": "5fc3d24a"
      },
      "outputs": [],
      "source": [
        "def create_loss_landscapes(model, training_loader, testing_loader, device, graph_title):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    training_historical_loss, testing_historical_loss = pre_train_and_test(model, training_loader, testing_loader, criterion, optimizer)\n",
        "    #create_random_direction_loss_landscape(model, testing_loader, criterion, device, graph_title + \" Random Directions\")\n",
        "    create_pca_loss_landscape(model, training_loader, testing_loader, criterion, device, optimizer, graph_title + \" PCA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc888444",
      "metadata": {
        "id": "cc888444"
      },
      "outputs": [],
      "source": [
        "def create_VGG_loss_landscapes(training_loader, testing_loader, device):\n",
        "    vgg11 = models.vgg11(weights = models.VGG11_Weights.DEFAULT)\n",
        "    \n",
        "    # change the number of classes \n",
        "    vgg11.classifier[6].out_features = 10\n",
        "    \n",
        "    create_loss_landscapes(vgg11, training_loader, testing_loader, device, 'YGG')\n",
        "\n",
        "def create_ResNet_loss_landscapes(training_loader, testing_loader, device):\n",
        "    resnet50 = models.resnet50(weights = models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # change the number of classes \n",
        "    resnet50.fc.out_features = 10\n",
        "    \n",
        "    create_loss_landscapes(resnet50, training_loader, testing_loader, device, 'ResNet')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe34e579",
      "metadata": {
        "id": "fe34e579"
      },
      "source": [
        "# Orchestration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "id": "db62ed37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "db62ed37",
        "outputId": "c465752b-bf42-4a79-ad65-ab7a60dd34e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-184-1bc8f0d4b1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcreate_ResNet_loss_landscapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcreate_VGG_loss_landscapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-182-f746d1c0e0fa>\u001b[0m in \u001b[0;36mcreate_ResNet_loss_landscapes\u001b[0;34m(training_loader, testing_loader, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcreate_loss_landscapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ResNet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-181-d30e422f7b02>\u001b[0m in \u001b[0;36mcreate_loss_landscapes\u001b[0;34m(model, training_loader, testing_loader, device, graph_title)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_loss_landscapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtraining_historical_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_historical_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_train_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    924\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 14.76 GiB total capacity; 13.48 GiB already allocated; 3.75 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "training_data, testing_data = get_data()\n",
        "training_loader, testing_loader = get_loaders(training_data, testing_data, 10)\n",
        "classes = training_data.classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "create_ResNet_loss_landscapes(training_loader, testing_loader, device)\n",
        "create_VGG_loss_landscapes(training_loader, testing_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c0810b5",
      "metadata": {
        "id": "9c0810b5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}