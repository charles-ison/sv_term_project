{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f128708d618048acabcd6e4dc5b2b6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a18a1bae1a1d429a9a37420d6f8b7029",
              "IPY_MODEL_de35763c158f4ba698b05149141027f3",
              "IPY_MODEL_ac83426a300f437990c0d3aef1851485"
            ],
            "layout": "IPY_MODEL_eca86f436d3d4873a37d224552dd4f46"
          }
        },
        "a18a1bae1a1d429a9a37420d6f8b7029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e496127336f4d2d8e0e18d6ca7fe6b3",
            "placeholder": "​",
            "style": "IPY_MODEL_ac63e442b9da4277a2f1f3ed25ec2563",
            "value": "100%"
          }
        },
        "de35763c158f4ba698b05149141027f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38e273c629634a36a0270b5ed0307bd1",
            "max": 102540417,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32eb3496870046e89946256be8631e15",
            "value": 102540417
          }
        },
        "ac83426a300f437990c0d3aef1851485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2699c3c669724ef19489e54371bea4d5",
            "placeholder": "​",
            "style": "IPY_MODEL_fd3e9fae9aad444394d61c6a188c78dd",
            "value": " 97.8M/97.8M [00:02&lt;00:00, 58.2MB/s]"
          }
        },
        "eca86f436d3d4873a37d224552dd4f46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e496127336f4d2d8e0e18d6ca7fe6b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac63e442b9da4277a2f1f3ed25ec2563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38e273c629634a36a0270b5ed0307bd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32eb3496870046e89946256be8631e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2699c3c669724ef19489e54371bea4d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3e9fae9aad444394d61c6a188c78dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install plyfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqXmsdKJpVqv",
        "outputId": "3407106c-768c-4723-dde1-6b31a38754ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting plyfile\n",
            "  Downloading plyfile-0.7.4-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.8/dist-packages (from plyfile) (1.21.6)\n",
            "Installing collected packages: plyfile\n",
            "Successfully installed plyfile-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from plyfile import PlyData, PlyElement\n",
        "import csv"
      ],
      "metadata": {
        "id": "9KL9nUitbYwh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting to PLY"
      ],
      "metadata": {
        "id": "-uWpw4u_VXWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_vertex_data_from_arr(X, Y, Z):\n",
        "    \"\"\"Returns a PlyElement listing each vertex of data.\"\"\"\n",
        "\n",
        "    # Create a list of vertices.\n",
        "    vertex_data_points = []\n",
        "\n",
        "    for r_idx in range(len(Y)):\n",
        "        for c_idx in range(len(Y[0])):\n",
        "            z, vx, vy, vz = 0, 0.0, 0.0, 0.0\n",
        "            \n",
        "            x = X[r_idx][c_idx]\n",
        "            y = Y[r_idx][c_idx]\n",
        "            s = Z[r_idx][c_idx]\n",
        "            vertex_data_points.append((x, y, z, vx, vy, vz, s))\n",
        "        \n",
        "    # Export the list of vertices.\n",
        "    # numpy data types: ['int8', 'i1', 'char', 'uint8', 'u1', 'uchar', 'b1', 'int16', 'i2', 'short', 'uint16', 'u2', 'ushort', 'int32', 'i4', 'int', 'uint32', 'u4', 'uint', 'float32', 'f4', 'float', 'float64', 'f8', 'double']\n",
        "    vertices = np.array(vertex_data_points,\n",
        "                         dtype=[('x', 'float64'), ('y', 'float64'), ('z', 'float64'),\n",
        "                                ('vx', 'float64'), ('vy', 'float64'), ('vz', 'float64'),\n",
        "                                ('s', 'float64')])\n",
        "\n",
        "    return PlyElement.describe(vertices, 'vertex')"
      ],
      "metadata": {
        "id": "jRT-mX3LXow5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_face_data(num_rows):\n",
        "    \"\"\"Returns a PlyElement listing all of the faces of a square plane.\n",
        "       Params:\n",
        "            - num_rows = an int equal to the number of rows/cols of data, i.e. number of vertices in a direction.\n",
        "    \"\"\"\n",
        "    row_size = num_rows - 1\n",
        "    num_faces = row_size**2\n",
        "\n",
        "    # For every face, insert it into `data` as a tuple, which we will turn into a PlyElement.\n",
        "    data = []\n",
        "    x = 0\n",
        "    while x < num_faces + row_size:\n",
        "        if x % row_size - (x // row_size - 1) == 0:\n",
        "            x += 1\n",
        "            continue\n",
        "\n",
        "        next_row_offset = row_size + 2 + x\n",
        "        data.append(([x, x + 1, next_row_offset, next_row_offset - 1]))\n",
        "        x += 1\n",
        "\n",
        "    face_data = np.array(data,\n",
        "                            dtype=[('vertex_indices', 'int32', (4,))])\n",
        "\n",
        "    # PlyElement.describe requires a one-dimensional structured array, so we have to do this in two lines.\n",
        "    ply_faces = np.empty(len(face_data),\n",
        "                            dtype=[('vertex_indices', 'int32', (4,))])\n",
        "    ply_faces['vertex_indices'] = face_data\n",
        "\n",
        "    element_2 = PlyElement.describe(ply_faces, 'face')\n",
        "    return element_2"
      ],
      "metadata": {
        "id": "131_y_2kXCT9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_ply(name, X, Y, Z):\n",
        "    \"\"\"Outputs a ply file for a square scalar field of vertices at (x = X[i], y = Y[i], s = Z[i]).\"\"\"\n",
        "\n",
        "    output_filename = f'new_data_{name}.ply'\n",
        "    # Generate the face and vertex elements.\n",
        "    num_rows = len(X)\n",
        "    vertex_element = generate_vertex_data_from_arr(X, Y, Z)\n",
        "    face_element = generate_face_data(num_rows)\n",
        "\n",
        "    # Create a PlyData object and write it to a file.\n",
        "    new_ply_data = PlyData([vertex_element, face_element], text=True)\n",
        "    new_ply_data.write(output_filename)\n",
        "\n",
        "    print(f\"Saved to {output_filename}\")"
      ],
      "metadata": {
        "id": "CatnM-GtXH7l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "u_PRdvgmVYP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "Chw9WcBEVaDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    \n",
        "    training_data = torchvision.datasets.CIFAR10(root = 'data',\n",
        "                                               train = True,\n",
        "                                               transform = transform,\n",
        "                                               download = True)\n",
        "\n",
        "    testing_data = torchvision.datasets.CIFAR10(root = 'data',\n",
        "                                              train = False,\n",
        "                                              transform = transform,\n",
        "                                              download=True)\n",
        "    \n",
        "    return training_data, testing_data\n",
        "\n",
        "def get_loaders(training_data, testing_data, batch_size):\n",
        "    training_loader = torch.utils.data.DataLoader(dataset = training_data,\n",
        "                                                  batch_size = batch_size,\n",
        "                                                  shuffle = True)\n",
        "\n",
        "    testing_loader = torch.utils.data.DataLoader(dataset = testing_data,\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 shuffle = True)\n",
        "    \n",
        "    return training_loader, testing_loader"
      ],
      "metadata": {
        "id": "qyIy4drE2BUt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, training_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    num_correct = 0\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # TODO: remove this, just here to cut down on running time\n",
        "        if(i == 100):\n",
        "            break\n",
        "\n",
        "        data, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, labels)\n",
        "        running_loss += loss.item()\n",
        "        _, predictions = torch.max(output.data, 1)\n",
        "        num_correct += (predictions == labels).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    # TODO: remove this, just here to cut down on running time\n",
        "    loss = running_loss/(10*100)\n",
        "    #loss = running_loss/len(training_loader.dataset)\n",
        "    accuracy = num_correct/ (10*100)\n",
        "    #accuracy = num_correct/len(training_loader.dataset)\n",
        "    print(f'Train Loss: {loss:.4f}, Train Acc: {accuracy:.2f}')\n",
        "    \n",
        "    return loss, accuracy\n",
        "\n",
        "def test(model, testing_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    num_correct = 0\n",
        "    for i, data in enumerate(testing_loader):\n",
        "        # TODO: remove this, just here to cut down on running time\n",
        "        if(i == 100):\n",
        "            break\n",
        "\n",
        "        data, labels = data[0].to(device), data[1].to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, labels)\n",
        "        running_loss += loss.item()\n",
        "        _, predictions = torch.max(output.data, 1)\n",
        "        num_correct += (predictions == labels).sum().item()\n",
        "    \n",
        "    # TODO: remove this, just here to cut down on running time\n",
        "    loss = running_loss/(10*100)\n",
        "    #loss = running_loss/len(testing_loader.dataset)\n",
        "    accuracy = num_correct/(10*100)\n",
        "    #accuracy = num_correct/len(testing_loader.dataset)\n",
        "    print(f'Test Loss: {loss:.4f}, Test Acc: {accuracy:.2f}')\n",
        "    \n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "def get_training_loss(model, training_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # TODO: remove this, just here to cut down on running time\n",
        "        if(i == 100):\n",
        "            break\n",
        "\n",
        "        data, labels = data[0].to(device), data[1].to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, labels)\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # TODO: remove this, just here to cut down on running time\n",
        "    loss = running_loss/(10*100)\n",
        "    #loss = running_loss/len(training_loader.dataset)\n",
        "    print(f'Training Loss: {loss:.4f}')\n",
        "    \n",
        "    return loss\n",
        "\n",
        "def pre_train_and_test(model, training_loader, testing_loader, criterion, optimizer):\n",
        "\n",
        "    historical_weights = []\n",
        "    historical_losses = []\n",
        "\n",
        "    for epoch in range(10):\n",
        "        print(\"epoch: \" + str(epoch))\n",
        "        training_loss, training_accuracy = train(model, training_loader, criterion, optimizer)\n",
        "        testing_loss, testing_accuracy = test(model, testing_loader, criterion)\n",
        "\n",
        "        training_weights = get_weights(model)\n",
        "        historical_weights.append(copy.deepcopy(training_weights))\n",
        "        historical_losses.append(training_loss)\n",
        "\n",
        "    return historical_weights[:-1], historical_losses[:-1]"
      ],
      "metadata": {
        "id": "wpeG79qU2Tdh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weights(model):\n",
        "    return [param.data for param in model.parameters()]\n",
        "\n",
        "def get_random_directions(weights, device):\n",
        "    return [torch.randn(w.size()).to(device) for w in weights]\n",
        "\n",
        "def normalize_directions(directions, weights):\n",
        "    for d, w in zip(directions, weights):\n",
        "        d.mul_(w.norm()/(d.norm() + 1e-10))\n",
        "\n",
        "def tensorlist_to_tensor(weights):\n",
        "    return torch.cat([w.cpu().view(w.cpu().numel()) if w.dim() > 1 else torch.FloatTensor(w.cpu()) for w in weights])\n",
        "\n",
        "def get_diff_weights(final_weights, historical_weights):\n",
        "    return [h2 - fw for (fw, h2) in zip(final_weights, historical_weights)]"
      ],
      "metadata": {
        "id": "leviCT9H2X0k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_figure(X, Y, Z, title):\n",
        "    fig = plt.figure(figsize=(10,7.5))\n",
        "    ax0 = fig.add_subplot(projection='3d' )\n",
        "\n",
        "    ax0.view_init(elev=30, azim=-20)\n",
        "    ax0.set_xlabel('X', labelpad=9)\n",
        "    ax0.set_ylabel('Y', labelpad=-5)\n",
        "    ax0.set_zlabel(\"Loss\", labelpad=-30)\n",
        "    ax0.tick_params(axis='x', pad=5, which='major')\n",
        "    ax0.tick_params(axis='y', pad=-5, which='major')\n",
        "    ax0.tick_params(axis='z', pad=5, which='major')\n",
        "    ax0.set_title(title, y=0.85)\n",
        "    ax0.plot_surface(X, Y, Z, cmap='terrain', antialiased=True, cstride=1, rstride=1, alpha=0.75)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2f_sXj3Q3cRb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_direction_losses(model, training_loader, testing_loader, criterion, device):\n",
        "    \n",
        "    weights = get_weights(model)\n",
        "\n",
        "    random_x_directions = get_random_directions(weights, device);\n",
        "    random_y_directions = get_random_directions(weights, device);\n",
        "\n",
        "    normalize_directions(random_x_directions, weights);\n",
        "    normalize_directions(random_y_directions, weights);\n",
        "\n",
        "    x_coordinates = np.arange(-0.1, 0.11, 0.01)   \n",
        "    y_coordinates = np.arange(-0.1, 0.11, 0.01)   \n",
        "    X, Y = np.meshgrid(x_coordinates, y_coordinates)\n",
        "    Z = np.zeros((x_coordinates.size, y_coordinates.size))\n",
        "\n",
        "    for y_index, y in enumerate(y_coordinates):\n",
        "        for x_index, x in enumerate(x_coordinates):\n",
        "        \n",
        "            print(\"X: \" + str(x) + \", Y: \" + str(y))\n",
        "            updated_x_directions = [direction * x for direction in random_x_directions]\n",
        "            updated_y_directions = [direction * y for direction in random_y_directions]\n",
        "            delta = [sum(direction) for direction in zip(updated_x_directions, updated_y_directions)]\n",
        "            old_weights = copy.deepcopy(get_weights(model))\n",
        "        \n",
        "            for (p, w, d) in zip(model.parameters(), old_weights, delta):\n",
        "                p.data = w + torch.Tensor(d).type(type(w)).to(device)\n",
        "            \n",
        "            training_loss = get_training_loss(model, training_loader, criterion)\n",
        "            Z[y_index][x_index] = training_loss\n",
        "        \n",
        "            for (p, w) in zip(model.parameters(), old_weights):\n",
        "                p.data = w\n",
        "                \n",
        "    return X, Y, Z"
      ],
      "metadata": {
        "id": "6aAkG2o73fwu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pca_to_directions(pca, weights):\n",
        "      directions = copy.deepcopy(weights)\n",
        "      idx = 0\n",
        "      for w in directions:\n",
        "          w.copy_(torch.tensor(pca[idx:idx + w.numel()]).view(w.size()))\n",
        "          idx += w.numel()\n",
        "      return directions\n",
        "\n",
        "def write_gradient_descent_results_to_csv(weight_change_directions, pca_x_directions, pca_y_directions):\n",
        "    pca_x_directions = tensorlist_to_tensor(pca_x_directions)\n",
        "    pca_y_directions = tensorlist_to_tensor(pca_y_directions)\n",
        "    with open('gradient_descent_results.csv', 'w', encoding='UTF8') as file:\n",
        "        writter = csv.writer(file)\n",
        "        for weight in zip(weight_change_directions):\n",
        "            x = np.dot(weight, pca_x_directions)/pca_x_directions.norm()\n",
        "            y = np.dot(weight, pca_y_directions)/pca_y_directions.norm()         \n",
        "            writter.writerow([x.item(), y.item()])"
      ],
      "metadata": {
        "id": "Uv-q7D0a3i3I"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pca_losses(model, training_loader, testing_loader, criterion, device, optimizer, historical_weights):\n",
        "\n",
        "    weight_change_directions = []\n",
        "    for weight in historical_weights:\n",
        "      weight_change_direction = get_diff_weights(historical_weights[-1], weight)\n",
        "      weight_change_directions.append(tensorlist_to_tensor(weight_change_direction).numpy())\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    weight_change_directions = np.array(weight_change_directions)\n",
        "    pca.fit(weight_change_directions)\n",
        "    pca1 = np.array(pca.components_[0])\n",
        "    pca2 = np.array(pca.components_[1])\n",
        "\n",
        "    pca_x_directions = pca_to_directions(pca1, historical_weights[-1])\n",
        "    pca_y_directions = pca_to_directions(pca2, historical_weights[-1])\n",
        "    write_gradient_descent_results_to_csv(weight_change_directions, pca_x_directions, pca_y_directions)\n",
        "\n",
        "    x_coordinates = np.arange(-0.1, 0.11, 0.01)   \n",
        "    y_coordinates = np.arange(-0.1, 0.11, 0.01)   \n",
        "\n",
        "    X, Y = np.meshgrid(x_coordinates, y_coordinates)\n",
        "    Z = np.zeros((x_coordinates.size, y_coordinates.size))\n",
        "\n",
        "    for y_index, y in enumerate(y_coordinates):\n",
        "        for x_index, x in enumerate(x_coordinates):\n",
        "\n",
        "            print(\"X: \" + str(x) + \", Y: \" + str(y))\n",
        "            updated_x_directions = [direction * x for direction in pca_x_directions]\n",
        "            updated_y_directions = [direction * y for direction in pca_y_directions]\n",
        "            delta = [sum(direction) for direction in zip(updated_x_directions, updated_y_directions)]\n",
        "            old_weights = copy.deepcopy(get_weights(model))\n",
        "\n",
        "            for (p, w, d) in zip(model.parameters(), old_weights, delta):\n",
        "                p.data = w + torch.Tensor(d).type(type(w)).to(device)\n",
        "            \n",
        "            training_loss = get_training_loss(model, training_loader, criterion)\n",
        "            Z[y_index][x_index] = training_loss\n",
        "        \n",
        "            for (p, w) in zip(model.parameters(), old_weights):\n",
        "                p.data = w\n",
        "        \n",
        "    return X, Y, Z"
      ],
      "metadata": {
        "id": "1-vlMGag3ky9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_random_direction_loss_landscape(model, training_loader, testing_loader, criterion, device, graph_title):\n",
        "    X, Y, Z = get_random_direction_losses(model, training_loader, testing_loader, criterion, device)\n",
        "    plot_figure(X, Y, Z, graph_title)\n",
        "    output_ply(f\"{graph_title.replace(' ', '_')}_random\", X, Y, Z)\n",
        "\n",
        "def create_pca_loss_landscape(model, training_loader, testing_loader, criterion, device, optimizer, historical_weights, graph_title):\n",
        "    X, Y, Z = get_pca_losses(model, training_loader, testing_loader, criterion, device, optimizer, historical_weights)\n",
        "    plot_figure(X, Y, Z, graph_title)\n",
        "    output_ply(f\"{graph_title.replace(' ', '_')}_pca\", X, Y, Z)\n"
      ],
      "metadata": {
        "id": "VdxLGQz83nu_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_loss_landscapes(model, training_loader, testing_loader, device, graph_title):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    historical_weights, historical_losses = pre_train_and_test(model, training_loader, testing_loader, criterion, optimizer)\n",
        "    create_pca_loss_landscape(model, training_loader, testing_loader, criterion, device, optimizer, historical_weights, graph_title + \" PCA\")\n",
        "    create_random_direction_loss_landscape(model, training_loader, testing_loader, criterion, device, graph_title + \" Random Directions\")\n"
      ],
      "metadata": {
        "id": "ZBTEy1kg3pem"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_VGG_loss_landscapes(training_loader, testing_loader, device):\n",
        "    vgg11 = models.vgg11(weights = models.VGG11_Weights.DEFAULT)\n",
        "    \n",
        "    # change the number of classes \n",
        "    vgg11.classifier[6].out_features = 10\n",
        "    \n",
        "    create_loss_landscapes(vgg11, training_loader, testing_loader, device, 'YGG')\n",
        "\n",
        "def create_ResNet_loss_landscapes(training_loader, testing_loader, device):\n",
        "    resnet50 = models.resnet50(weights = models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # change the number of classes \n",
        "    resnet50.fc.out_features = 10\n",
        "    \n",
        "    create_loss_landscapes(resnet50, training_loader, testing_loader, device, 'ResNet')"
      ],
      "metadata": {
        "id": "678WuU6g3tuV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, testing_data = get_data()\n",
        "training_loader, testing_loader = get_loaders(training_data, testing_data, 10)\n",
        "classes = training_data.classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "create_VGG_loss_landscapes(training_loader, testing_loader, device)\n",
        "create_ResNet_loss_landscapes(training_loader, testing_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f128708d618048acabcd6e4dc5b2b6c2",
            "a18a1bae1a1d429a9a37420d6f8b7029",
            "de35763c158f4ba698b05149141027f3",
            "ac83426a300f437990c0d3aef1851485",
            "eca86f436d3d4873a37d224552dd4f46",
            "4e496127336f4d2d8e0e18d6ca7fe6b3",
            "ac63e442b9da4277a2f1f3ed25ec2563",
            "38e273c629634a36a0270b5ed0307bd1",
            "32eb3496870046e89946256be8631e15",
            "2699c3c669724ef19489e54371bea4d5",
            "fd3e9fae9aad444394d61c6a188c78dd"
          ]
        },
        "id": "89jqZ2L-3yeo",
        "outputId": "4e67f057-c46b-4361-f3b3-bc7f843009b7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f128708d618048acabcd6e4dc5b2b6c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\n",
            "Train Loss: 0.4264, Train Acc: 0.20\n",
            "Test Loss: 0.1955, Test Acc: 0.42\n",
            "epoch: 1\n",
            "Train Loss: 0.1561, Train Acc: 0.47\n",
            "Test Loss: 0.1034, Test Acc: 0.68\n",
            "epoch: 2\n",
            "Train Loss: 0.1001, Train Acc: 0.68\n",
            "Test Loss: 0.0772, Test Acc: 0.76\n",
            "epoch: 3\n",
            "Train Loss: 0.0833, Train Acc: 0.72\n",
            "Test Loss: 0.0599, Test Acc: 0.81\n",
            "epoch: 4\n",
            "Train Loss: 0.0707, Train Acc: 0.76\n",
            "Test Loss: 0.0468, Test Acc: 0.84\n",
            "epoch: 5\n",
            "Train Loss: 0.0637, Train Acc: 0.79\n",
            "Test Loss: 0.0441, Test Acc: 0.86\n",
            "epoch: 6\n",
            "Train Loss: 0.0610, Train Acc: 0.79\n",
            "Test Loss: 0.0408, Test Acc: 0.88\n",
            "epoch: 7\n",
            "Train Loss: 0.0486, Train Acc: 0.84\n",
            "Test Loss: 0.0392, Test Acc: 0.87\n",
            "epoch: 8\n",
            "Train Loss: 0.0541, Train Acc: 0.82\n",
            "Test Loss: 0.0350, Test Acc: 0.88\n",
            "epoch: 9\n",
            "Train Loss: 0.0488, Train Acc: 0.84\n",
            "Test Loss: 0.0320, Test Acc: 0.90\n",
            "X: -0.1, Y: -0.1\n",
            "Training Loss: 0.0313\n",
            "X: -0.09000000000000001, Y: -0.1\n",
            "Training Loss: 0.0314\n",
            "X: -0.08000000000000002, Y: -0.1\n",
            "Training Loss: 0.0335\n",
            "X: -0.07000000000000002, Y: -0.1\n",
            "Training Loss: 0.0313\n",
            "X: -0.060000000000000026, Y: -0.1\n",
            "Training Loss: 0.0310\n",
            "X: -0.05000000000000003, Y: -0.1\n",
            "Training Loss: 0.0308\n",
            "X: -0.040000000000000036, Y: -0.1\n",
            "Training Loss: 0.0328\n",
            "X: -0.03000000000000004, Y: -0.1\n",
            "Training Loss: 0.0374\n",
            "X: -0.020000000000000046, Y: -0.1\n",
            "Training Loss: 0.0305\n",
            "X: -0.01000000000000005, Y: -0.1\n",
            "Training Loss: 0.0330\n",
            "X: -5.551115123125783e-17, Y: -0.1\n",
            "Training Loss: 0.0342\n",
            "X: 0.00999999999999994, Y: -0.1\n",
            "Training Loss: 0.0311\n",
            "X: 0.019999999999999934, Y: -0.1\n",
            "Training Loss: 0.0276\n",
            "X: 0.029999999999999943, Y: -0.1\n",
            "Training Loss: 0.0341\n",
            "X: 0.039999999999999925, Y: -0.1\n",
            "Training Loss: 0.0299\n",
            "X: 0.049999999999999906, Y: -0.1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-63816c9fcb36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#create_VGG_loss_landscapes(training_loader, testing_loader, device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcreate_ResNet_loss_landscapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-f746d1c0e0fa>\u001b[0m in \u001b[0;36mcreate_ResNet_loss_landscapes\u001b[0;34m(training_loader, testing_loader, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcreate_loss_landscapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ResNet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-ba14ea4f38c6>\u001b[0m in \u001b[0;36mcreate_loss_landscapes\u001b[0;34m(model, training_loader, testing_loader, device, graph_title)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhistorical_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistorical_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_train_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcreate_pca_loss_landscape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistorical_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_title\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" PCA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcreate_random_direction_loss_landscape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_title\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Random Directions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-763da93533e4>\u001b[0m in \u001b[0;36mcreate_pca_loss_landscape\u001b[0;34m(model, training_loader, testing_loader, criterion, device, optimizer, historical_weights, graph_title)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_pca_loss_landscape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistorical_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pca_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistorical_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplot_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutput_ply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{graph_title.replace(' ', '_')}_pca\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-23c02c1f82b9>\u001b[0m in \u001b[0;36mget_pca_losses\u001b[0;34m(model, training_loader, testing_loader, criterion, device, optimizer, historical_weights)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mtraining_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6f205a207daf>\u001b[0m in \u001b[0;36mget_training_loss\u001b[0;34m(model, training_loader, criterion)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;31m# TODO: remove this, just here to cut down on running time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'Image'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MnFhuIILpnHs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}