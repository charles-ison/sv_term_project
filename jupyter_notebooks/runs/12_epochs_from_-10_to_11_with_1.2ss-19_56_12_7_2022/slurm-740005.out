getting data
Files already downloaded and verified
Files already downloaded and verified
training VGG
epoch: 0
Train Loss: 0.3255, Train Acc: 0.13
Test Loss: 0.2277, Test Acc: 0.19
epoch: 1
Train Loss: 0.2186, Train Acc: 0.21
Test Loss: 0.1772, Test Acc: 0.36
epoch: 2
Train Loss: 0.1870, Train Acc: 0.31
Test Loss: 0.1725, Test Acc: 0.39
epoch: 3
Train Loss: 0.1576, Train Acc: 0.41
Test Loss: 0.1376, Test Acc: 0.49
epoch: 4
Train Loss: 0.1434, Train Acc: 0.49
Test Loss: 0.1424, Test Acc: 0.53
epoch: 5
Train Loss: 0.1290, Train Acc: 0.54
Test Loss: 0.1069, Test Acc: 0.60
epoch: 6
Train Loss: 0.1238, Train Acc: 0.55
Test Loss: 0.1109, Test Acc: 0.61
epoch: 7
Train Loss: 0.1132, Train Acc: 0.60
Test Loss: 0.0837, Test Acc: 0.70
epoch: 8
Train Loss: 0.1018, Train Acc: 0.64
Test Loss: 0.0829, Test Acc: 0.71
epoch: 9
Train Loss: 0.0879, Train Acc: 0.69
Test Loss: 0.0761, Test Acc: 0.74
epoch: 10
Train Loss: 0.0888, Train Acc: 0.69
Test Loss: 0.0891, Test Acc: 0.69
epoch: 11
Train Loss: 0.0836, Train Acc: 0.72
Test Loss: 0.0614, Test Acc: 0.79
X: -10.0, Y: -10.0
Training Loss: 6.6166
X: -8.8, Y: -10.0
Training Loss: 6.5351
X: -7.600000000000001, Y: -10.0
Training Loss: 6.2381
X: -6.400000000000002, Y: -10.0
Training Loss: 5.9286
X: -5.200000000000003, Y: -10.0
Training Loss: 6.3969
X: -4.0000000000000036, Y: -10.0
Training Loss: 7.2304
X: -2.8000000000000043, Y: -10.0
Training Loss: 8.0653
X: -1.600000000000005, Y: -10.0
Training Loss: 9.7858
X: -0.4000000000000057, Y: -10.0
Training Loss: 10.8356
X: 0.7999999999999936, Y: -10.0
Training Loss: 13.3439
X: 1.999999999999993, Y: -10.0
Training Loss: 15.2666
X: 3.199999999999992, Y: -10.0
Training Loss: 18.3196
X: 4.3999999999999915, Y: -10.0
Training Loss: 23.9650
X: 5.599999999999991, Y: -10.0
Training Loss: 33.0915
X: 6.79999999999999, Y: -10.0
Training Loss: 42.8296
X: 7.999999999999989, Y: -10.0
Training Loss: 58.7862
X: 9.199999999999989, Y: -10.0
Training Loss: 79.1149
X: 10.399999999999988, Y: -10.0
Training Loss: 101.7168
X: -10.0, Y: -8.8
Training Loss: 4.0203
X: -8.8, Y: -8.8
Training Loss: 3.7218
X: -7.600000000000001, Y: -8.8
Training Loss: 3.6535
X: -6.400000000000002, Y: -8.8
Training Loss: 3.3176
X: -5.200000000000003, Y: -8.8
Training Loss: 3.4576
X: -4.0000000000000036, Y: -8.8
Training Loss: 3.7785
X: -2.8000000000000043, Y: -8.8
Training Loss: 4.3065
X: -1.600000000000005, Y: -8.8
Training Loss: 4.8340
X: -0.4000000000000057, Y: -8.8
Training Loss: 5.7505
X: 0.7999999999999936, Y: -8.8
Training Loss: 6.7500
X: 1.999999999999993, Y: -8.8
Training Loss: 8.6627
X: 3.199999999999992, Y: -8.8
Training Loss: 10.4121
X: 4.3999999999999915, Y: -8.8
Training Loss: 14.7346
X: 5.599999999999991, Y: -8.8
Training Loss: 19.2247
X: 6.79999999999999, Y: -8.8
Training Loss: 27.0506
X: 7.999999999999989, Y: -8.8
Training Loss: 34.9291
X: 9.199999999999989, Y: -8.8
Training Loss: 49.8492
X: 10.399999999999988, Y: -8.8
Training Loss: 63.5459
X: -10.0, Y: -7.600000000000001
Training Loss: 2.5388
X: -8.8, Y: -7.600000000000001
Training Loss: 2.2383
X: -7.600000000000001, Y: -7.600000000000001
Training Loss: 1.9661
X: -6.400000000000002, Y: -7.600000000000001
Training Loss: 1.8784
X: -5.200000000000003, Y: -7.600000000000001
Training Loss: 1.7950
X: -4.0000000000000036, Y: -7.600000000000001
Training Loss: 1.8835
X: -2.8000000000000043, Y: -7.600000000000001
Training Loss: 2.2944
X: -1.600000000000005, Y: -7.600000000000001
Training Loss: 2.5028
X: -0.4000000000000057, Y: -7.600000000000001
Training Loss: 2.9231
X: 0.7999999999999936, Y: -7.600000000000001
Training Loss: 3.6285
X: 1.999999999999993, Y: -7.600000000000001
Training Loss: 4.4955
X: 3.199999999999992, Y: -7.600000000000001
Training Loss: 5.8940
X: 4.3999999999999915, Y: -7.600000000000001
Training Loss: 8.1573
X: 5.599999999999991, Y: -7.600000000000001
Training Loss: 11.2328
X: 6.79999999999999, Y: -7.600000000000001
Training Loss: 16.6018
X: 7.999999999999989, Y: -7.600000000000001
Training Loss: 21.7539
X: 9.199999999999989, Y: -7.600000000000001
Training Loss: 29.2120
X: 10.399999999999988, Y: -7.600000000000001
Training Loss: 37.7650
X: -10.0, Y: -6.400000000000002
Training Loss: 1.7478
X: -8.8, Y: -6.400000000000002
Training Loss: 1.3015
X: -7.600000000000001, Y: -6.400000000000002
Training Loss: 1.1372
X: -6.400000000000002, Y: -6.400000000000002
Training Loss: 1.0553
X: -5.200000000000003, Y: -6.400000000000002
Training Loss: 1.0223
X: -4.0000000000000036, Y: -6.400000000000002
Training Loss: 1.0677
X: -2.8000000000000043, Y: -6.400000000000002
Training Loss: 1.0623
X: -1.600000000000005, Y: -6.400000000000002
Training Loss: 1.2356
X: -0.4000000000000057, Y: -6.400000000000002
Training Loss: 1.5218
X: 0.7999999999999936, Y: -6.400000000000002
Training Loss: 1.7198
X: 1.999999999999993, Y: -6.400000000000002
Training Loss: 2.4216
X: 3.199999999999992, Y: -6.400000000000002
Training Loss: 3.1590
X: 4.3999999999999915, Y: -6.400000000000002
Training Loss: 4.6925
X: 5.599999999999991, Y: -6.400000000000002
Training Loss: 6.3833
X: 6.79999999999999, Y: -6.400000000000002
Training Loss: 9.5328
X: 7.999999999999989, Y: -6.400000000000002
Training Loss: 12.6467
X: 9.199999999999989, Y: -6.400000000000002
Training Loss: 17.0705
X: 10.399999999999988, Y: -6.400000000000002
Training Loss: 24.0149
X: -10.0, Y: -5.200000000000003
Training Loss: 1.1666
X: -8.8, Y: -5.200000000000003
Training Loss: 0.8477
X: -7.600000000000001, Y: -5.200000000000003
Training Loss: 0.6569
X: -6.400000000000002, Y: -5.200000000000003
Training Loss: 0.6280
X: -5.200000000000003, Y: -5.200000000000003
Training Loss: 0.5302
X: -4.0000000000000036, Y: -5.200000000000003
Training Loss: 0.5309
X: -2.8000000000000043, Y: -5.200000000000003
Training Loss: 0.5377
X: -1.600000000000005, Y: -5.200000000000003
Training Loss: 0.6171
X: -0.4000000000000057, Y: -5.200000000000003
Training Loss: 0.6517
X: 0.7999999999999936, Y: -5.200000000000003
Training Loss: 0.9354
X: 1.999999999999993, Y: -5.200000000000003
Training Loss: 1.2528
X: 3.199999999999992, Y: -5.200000000000003
Training Loss: 1.7022
X: 4.3999999999999915, Y: -5.200000000000003
Training Loss: 2.6114
X: 5.599999999999991, Y: -5.200000000000003
Training Loss: 3.6496
X: 6.79999999999999, Y: -5.200000000000003
Training Loss: 5.6044
X: 7.999999999999989, Y: -5.200000000000003
Training Loss: 7.5964
X: 9.199999999999989, Y: -5.200000000000003
Training Loss: 10.6502
X: 10.399999999999988, Y: -5.200000000000003
Training Loss: 14.2686
X: -10.0, Y: -4.0000000000000036
Training Loss: 0.9224
X: -8.8, Y: -4.0000000000000036
Training Loss: 0.5877
X: -7.600000000000001, Y: -4.0000000000000036
Training Loss: 0.4558
X: -6.400000000000002, Y: -4.0000000000000036
Training Loss: 0.3819
X: -5.200000000000003, Y: -4.0000000000000036
Training Loss: 0.3278
X: -4.0000000000000036, Y: -4.0000000000000036
Training Loss: 0.2825
X: -2.8000000000000043, Y: -4.0000000000000036
Training Loss: 0.2566
X: -1.600000000000005, Y: -4.0000000000000036
Training Loss: 0.2786
X: -0.4000000000000057, Y: -4.0000000000000036
Training Loss: 0.3055
X: 0.7999999999999936, Y: -4.0000000000000036
Training Loss: 0.3892
X: 1.999999999999993, Y: -4.0000000000000036
Training Loss: 0.5489
X: 3.199999999999992, Y: -4.0000000000000036
Training Loss: 0.7833
X: 4.3999999999999915, Y: -4.0000000000000036
Training Loss: 1.2053
X: 5.599999999999991, Y: -4.0000000000000036
Training Loss: 2.0932
X: 6.79999999999999, Y: -4.0000000000000036
Training Loss: 3.3214
X: 7.999999999999989, Y: -4.0000000000000036
Training Loss: 4.6076
X: 9.199999999999989, Y: -4.0000000000000036
Training Loss: 6.3709
X: 10.399999999999988, Y: -4.0000000000000036
Training Loss: 8.7265
X: -10.0, Y: -2.8000000000000043
Training Loss: 0.7646
X: -8.8, Y: -2.8000000000000043
Training Loss: 0.4920
X: -7.600000000000001, Y: -2.8000000000000043
Training Loss: 0.3391
X: -6.400000000000002, Y: -2.8000000000000043
Training Loss: 0.2646
X: -5.200000000000003, Y: -2.8000000000000043
Training Loss: 0.2236
X: -4.0000000000000036, Y: -2.8000000000000043
Training Loss: 0.1892
X: -2.8000000000000043, Y: -2.8000000000000043
Training Loss: 0.1486
X: -1.600000000000005, Y: -2.8000000000000043
Training Loss: 0.1436
X: -0.4000000000000057, Y: -2.8000000000000043
Training Loss: 0.1374
X: 0.7999999999999936, Y: -2.8000000000000043
Training Loss: 0.1814
X: 1.999999999999993, Y: -2.8000000000000043
Training Loss: 0.2299
X: 3.199999999999992, Y: -2.8000000000000043
Training Loss: 0.3951
X: 4.3999999999999915, Y: -2.8000000000000043
Training Loss: 0.6213
X: 5.599999999999991, Y: -2.8000000000000043
Training Loss: 1.2031
X: 6.79999999999999, Y: -2.8000000000000043
Training Loss: 1.8897
X: 7.999999999999989, Y: -2.8000000000000043
Training Loss: 2.8922
X: 9.199999999999989, Y: -2.8000000000000043
Training Loss: 4.0642
X: 10.399999999999988, Y: -2.8000000000000043
Training Loss: 5.9719
X: -10.0, Y: -1.600000000000005
Training Loss: 0.7123
X: -8.8, Y: -1.600000000000005
Training Loss: 0.4347
X: -7.600000000000001, Y: -1.600000000000005
Training Loss: 0.2816
X: -6.400000000000002, Y: -1.600000000000005
Training Loss: 0.2272
X: -5.200000000000003, Y: -1.600000000000005
Training Loss: 0.1917
X: -4.0000000000000036, Y: -1.600000000000005
Training Loss: 0.1594
X: -2.8000000000000043, Y: -1.600000000000005
Training Loss: 0.1183
X: -1.600000000000005, Y: -1.600000000000005
Training Loss: 0.0914
X: -0.4000000000000057, Y: -1.600000000000005
Training Loss: 0.0804
X: 0.7999999999999936, Y: -1.600000000000005
Training Loss: 0.0906
X: 1.999999999999993, Y: -1.600000000000005
Training Loss: 0.1178
X: 3.199999999999992, Y: -1.600000000000005
Training Loss: 0.1833
X: 4.3999999999999915, Y: -1.600000000000005
Training Loss: 0.3557
X: 5.599999999999991, Y: -1.600000000000005
Training Loss: 0.6345
X: 6.79999999999999, Y: -1.600000000000005
Training Loss: 1.0686
X: 7.999999999999989, Y: -1.600000000000005
Training Loss: 1.7610
X: 9.199999999999989, Y: -1.600000000000005
Training Loss: 2.4406
X: 10.399999999999988, Y: -1.600000000000005
Training Loss: 3.4345
X: -10.0, Y: -0.4000000000000057
Training Loss: 1.0116
X: -8.8, Y: -0.4000000000000057
Training Loss: 0.4221
X: -7.600000000000001, Y: -0.4000000000000057
Training Loss: 0.2815
X: -6.400000000000002, Y: -0.4000000000000057
Training Loss: 0.2258
X: -5.200000000000003, Y: -0.4000000000000057
Training Loss: 0.1929
X: -4.0000000000000036, Y: -0.4000000000000057
Training Loss: 0.1689
X: -2.8000000000000043, Y: -0.4000000000000057
Training Loss: 0.1335
X: -1.600000000000005, Y: -0.4000000000000057
Training Loss: 0.0869
X: -0.4000000000000057, Y: -0.4000000000000057
Training Loss: 0.0623
X: 0.7999999999999936, Y: -0.4000000000000057
Training Loss: 0.0606
X: 1.999999999999993, Y: -0.4000000000000057
Training Loss: 0.0734
X: 3.199999999999992, Y: -0.4000000000000057
Training Loss: 0.1123
X: 4.3999999999999915, Y: -0.4000000000000057
Training Loss: 0.2052
X: 5.599999999999991, Y: -0.4000000000000057
Training Loss: 0.3454
X: 6.79999999999999, Y: -0.4000000000000057
Training Loss: 0.6227
X: 7.999999999999989, Y: -0.4000000000000057
Training Loss: 1.0546
X: 9.199999999999989, Y: -0.4000000000000057
Training Loss: 1.5955
X: 10.399999999999988, Y: -0.4000000000000057
Training Loss: 2.3749
X: -10.0, Y: 0.7999999999999936
Training Loss: 1.8692
X: -8.8, Y: 0.7999999999999936
Training Loss: 0.6626
X: -7.600000000000001, Y: 0.7999999999999936
Training Loss: 0.3300
X: -6.400000000000002, Y: 0.7999999999999936
Training Loss: 0.2491
X: -5.200000000000003, Y: 0.7999999999999936
Training Loss: 0.2178
X: -4.0000000000000036, Y: 0.7999999999999936
Training Loss: 0.1957
X: -2.8000000000000043, Y: 0.7999999999999936
Training Loss: 0.1750
X: -1.600000000000005, Y: 0.7999999999999936
Training Loss: 0.1136
X: -0.4000000000000057, Y: 0.7999999999999936
Training Loss: 0.0648
X: 0.7999999999999936, Y: 0.7999999999999936
Training Loss: 0.0614
X: 1.999999999999993, Y: 0.7999999999999936
Training Loss: 0.0668
X: 3.199999999999992, Y: 0.7999999999999936
Training Loss: 0.1039
X: 4.3999999999999915, Y: 0.7999999999999936
Training Loss: 0.1604
X: 5.599999999999991, Y: 0.7999999999999936
Training Loss: 0.2681
X: 6.79999999999999, Y: 0.7999999999999936
Training Loss: 0.4371
X: 7.999999999999989, Y: 0.7999999999999936
Training Loss: 0.6920
X: 9.199999999999989, Y: 0.7999999999999936
Training Loss: 1.1447
X: 10.399999999999988, Y: 0.7999999999999936
Training Loss: 1.6587
X: -10.0, Y: 1.999999999999993
Training Loss: 3.8674
X: -8.8, Y: 1.999999999999993
Training Loss: 1.2057
X: -7.600000000000001, Y: 1.999999999999993
Training Loss: 0.4793
X: -6.400000000000002, Y: 1.999999999999993
Training Loss: 0.2911
X: -5.200000000000003, Y: 1.999999999999993
Training Loss: 0.2535
X: -4.0000000000000036, Y: 1.999999999999993
Training Loss: 0.2361
X: -2.8000000000000043, Y: 1.999999999999993
Training Loss: 0.2125
X: -1.600000000000005, Y: 1.999999999999993
Training Loss: 0.1618
X: -0.4000000000000057, Y: 1.999999999999993
Training Loss: 0.0890
X: 0.7999999999999936, Y: 1.999999999999993
Training Loss: 0.0770
X: 1.999999999999993, Y: 1.999999999999993
Training Loss: 0.0953
X: 3.199999999999992, Y: 1.999999999999993
Training Loss: 0.1140
X: 4.3999999999999915, Y: 1.999999999999993
Training Loss: 0.1593
X: 5.599999999999991, Y: 1.999999999999993
Training Loss: 0.2504
X: 6.79999999999999, Y: 1.999999999999993
Training Loss: 0.4119
X: 7.999999999999989, Y: 1.999999999999993
Training Loss: 0.5939
X: 9.199999999999989, Y: 1.999999999999993
Training Loss: 0.8933
X: 10.399999999999988, Y: 1.999999999999993
Training Loss: 1.3251
X: -10.0, Y: 3.199999999999992
Training Loss: 7.9781
X: -8.8, Y: 3.199999999999992
Training Loss: 2.6364
X: -7.600000000000001, Y: 3.199999999999992
Training Loss: 0.9177
X: -6.400000000000002, Y: 3.199999999999992
Training Loss: 0.4235
X: -5.200000000000003, Y: 3.199999999999992
Training Loss: 0.3003
X: -4.0000000000000036, Y: 3.199999999999992
Training Loss: 0.2651
X: -2.8000000000000043, Y: 3.199999999999992
Training Loss: 0.2522
X: -1.600000000000005, Y: 3.199999999999992
Training Loss: 0.2202
X: -0.4000000000000057, Y: 3.199999999999992
Training Loss: 0.1531
X: 0.7999999999999936, Y: 3.199999999999992
Training Loss: 0.1279
X: 1.999999999999993, Y: 3.199999999999992
Training Loss: 0.1346
X: 3.199999999999992, Y: 3.199999999999992
Training Loss: 0.1705
X: 4.3999999999999915, Y: 3.199999999999992
Training Loss: 0.2203
X: 5.599999999999991, Y: 3.199999999999992
Training Loss: 0.2908
X: 6.79999999999999, Y: 3.199999999999992
Training Loss: 0.4269
X: 7.999999999999989, Y: 3.199999999999992
Training Loss: 0.6240
X: 9.199999999999989, Y: 3.199999999999992
Training Loss: 0.8925
X: 10.399999999999988, Y: 3.199999999999992
Training Loss: 1.2611
X: -10.0, Y: 4.3999999999999915
Training Loss: 15.9902
X: -8.8, Y: 4.3999999999999915
Training Loss: 6.0030
X: -7.600000000000001, Y: 4.3999999999999915
Training Loss: 2.0810
X: -6.400000000000002, Y: 4.3999999999999915
Training Loss: 0.8123
X: -5.200000000000003, Y: 4.3999999999999915
Training Loss: 0.4208
X: -4.0000000000000036, Y: 4.3999999999999915
Training Loss: 0.3255
X: -2.8000000000000043, Y: 4.3999999999999915
Training Loss: 0.2864
X: -1.600000000000005, Y: 4.3999999999999915
Training Loss: 0.2710
X: -0.4000000000000057, Y: 4.3999999999999915
Training Loss: 0.2275
X: 0.7999999999999936, Y: 4.3999999999999915
Training Loss: 0.2311
X: 1.999999999999993, Y: 4.3999999999999915
Training Loss: 0.2365
X: 3.199999999999992, Y: 4.3999999999999915
Training Loss: 0.2594
X: 4.3999999999999915, Y: 4.3999999999999915
Training Loss: 0.3076
X: 5.599999999999991, Y: 4.3999999999999915
Training Loss: 0.4095
X: 6.79999999999999, Y: 4.3999999999999915
Training Loss: 0.5466
X: 7.999999999999989, Y: 4.3999999999999915
Training Loss: 0.6841
X: 9.199999999999989, Y: 4.3999999999999915
Training Loss: 0.9749
X: 10.399999999999988, Y: 4.3999999999999915
Training Loss: 1.4253
X: -10.0, Y: 5.599999999999991
Training Loss: 33.8395
X: -8.8, Y: 5.599999999999991
Training Loss: 14.3911
X: -7.600000000000001, Y: 5.599999999999991
Training Loss: 5.4176
X: -6.400000000000002, Y: 5.599999999999991
Training Loss: 2.0350
X: -5.200000000000003, Y: 5.599999999999991
Training Loss: 0.8696
X: -4.0000000000000036, Y: 5.599999999999991
Training Loss: 0.5063
X: -2.8000000000000043, Y: 5.599999999999991
Training Loss: 0.3549
X: -1.600000000000005, Y: 5.599999999999991
Training Loss: 0.3133
X: -0.4000000000000057, Y: 5.599999999999991
Training Loss: 0.3009
X: 0.7999999999999936, Y: 5.599999999999991
Training Loss: 0.3689
X: 1.999999999999993, Y: 5.599999999999991
Training Loss: 0.4347
X: 3.199999999999992, Y: 5.599999999999991
Training Loss: 0.4296
X: 4.3999999999999915, Y: 5.599999999999991
Training Loss: 0.4779
X: 5.599999999999991, Y: 5.599999999999991
Training Loss: 0.5715
X: 6.79999999999999, Y: 5.599999999999991
Training Loss: 0.6956
X: 7.999999999999989, Y: 5.599999999999991
Training Loss: 0.8956
X: 9.199999999999989, Y: 5.599999999999991
Training Loss: 1.2607
X: 10.399999999999988, Y: 5.599999999999991
Training Loss: 1.6970
X: -10.0, Y: 6.79999999999999
Training Loss: 72.6902
X: -8.8, Y: 6.79999999999999
Training Loss: 31.8793
X: -7.600000000000001, Y: 6.79999999999999
Training Loss: 13.0190
X: -6.400000000000002, Y: 6.79999999999999
Training Loss: 5.0835
X: -5.200000000000003, Y: 6.79999999999999
Training Loss: 2.1286
X: -4.0000000000000036, Y: 6.79999999999999
Training Loss: 1.0412
X: -2.8000000000000043, Y: 6.79999999999999
Training Loss: 0.5942
X: -1.600000000000005, Y: 6.79999999999999
Training Loss: 0.4288
X: -0.4000000000000057, Y: 6.79999999999999
Training Loss: 0.3949
X: 0.7999999999999936, Y: 6.79999999999999
Training Loss: 0.4959
X: 1.999999999999993, Y: 6.79999999999999
Training Loss: 0.6757
X: 3.199999999999992, Y: 6.79999999999999
Training Loss: 0.7574
X: 4.3999999999999915, Y: 6.79999999999999
Training Loss: 0.8212
X: 5.599999999999991, Y: 6.79999999999999
Training Loss: 0.8331
X: 6.79999999999999, Y: 6.79999999999999
Training Loss: 1.0040
X: 7.999999999999989, Y: 6.79999999999999
Training Loss: 1.2929
X: 9.199999999999989, Y: 6.79999999999999
Training Loss: 1.6644
X: 10.399999999999988, Y: 6.79999999999999
Training Loss: 2.2804
X: -10.0, Y: 7.999999999999989
Training Loss: 138.4763
X: -8.8, Y: 7.999999999999989
Training Loss: 65.6648
X: -7.600000000000001, Y: 7.999999999999989
Training Loss: 29.6646
X: -6.400000000000002, Y: 7.999999999999989
Training Loss: 11.9930
X: -5.200000000000003, Y: 7.999999999999989
Training Loss: 5.1089
X: -4.0000000000000036, Y: 7.999999999999989
Training Loss: 2.4192
X: -2.8000000000000043, Y: 7.999999999999989
Training Loss: 1.2436
X: -1.600000000000005, Y: 7.999999999999989
Training Loss: 0.7603
X: -0.4000000000000057, Y: 7.999999999999989
Training Loss: 0.5884
X: 0.7999999999999936, Y: 7.999999999999989
Training Loss: 0.6552
X: 1.999999999999993, Y: 7.999999999999989
Training Loss: 0.8735
X: 3.199999999999992, Y: 7.999999999999989
Training Loss: 1.1318
X: 4.3999999999999915, Y: 7.999999999999989
Training Loss: 1.2604
X: 5.599999999999991, Y: 7.999999999999989
Training Loss: 1.3763
X: 6.79999999999999, Y: 7.999999999999989
Training Loss: 1.5504
X: 7.999999999999989, Y: 7.999999999999989
Training Loss: 1.9248
X: 9.199999999999989, Y: 7.999999999999989
Training Loss: 2.3991
X: 10.399999999999988, Y: 7.999999999999989
Training Loss: 3.2108
X: -10.0, Y: 9.199999999999989
Training Loss: 243.7267
X: -8.8, Y: 9.199999999999989
Training Loss: 123.7366
X: -7.600000000000001, Y: 9.199999999999989
Training Loss: 62.0043
X: -6.400000000000002, Y: 9.199999999999989
Training Loss: 28.0501
X: -5.200000000000003, Y: 9.199999999999989
Training Loss: 12.5420
X: -4.0000000000000036, Y: 9.199999999999989
Training Loss: 5.4984
X: -2.8000000000000043, Y: 9.199999999999989
Training Loss: 2.7812
X: -1.600000000000005, Y: 9.199999999999989
Training Loss: 1.5426
X: -0.4000000000000057, Y: 9.199999999999989
Training Loss: 1.0012
X: 0.7999999999999936, Y: 9.199999999999989
Training Loss: 0.9673
X: 1.999999999999993, Y: 9.199999999999989
Training Loss: 1.1973
X: 3.199999999999992, Y: 9.199999999999989
Training Loss: 1.5843
X: 4.3999999999999915, Y: 9.199999999999989
Training Loss: 1.8574
X: 5.599999999999991, Y: 9.199999999999989
Training Loss: 2.1921
X: 6.79999999999999, Y: 9.199999999999989
Training Loss: 2.4578
X: 7.999999999999989, Y: 9.199999999999989
Training Loss: 2.9893
X: 9.199999999999989, Y: 9.199999999999989
Training Loss: 3.4641
X: 10.399999999999988, Y: 9.199999999999989
Training Loss: 4.4277
X: -10.0, Y: 10.399999999999988
Training Loss: 426.9512
X: -8.8, Y: 10.399999999999988
Training Loss: 237.9606
X: -7.600000000000001, Y: 10.399999999999988
Training Loss: 116.1472
X: -6.400000000000002, Y: 10.399999999999988
Training Loss: 60.4911
X: -5.200000000000003, Y: 10.399999999999988
Training Loss: 27.9745
X: -4.0000000000000036, Y: 10.399999999999988
Training Loss: 12.4485
X: -2.8000000000000043, Y: 10.399999999999988
Training Loss: 5.8516
X: -1.600000000000005, Y: 10.399999999999988
Training Loss: 3.2534
X: -0.4000000000000057, Y: 10.399999999999988
Training Loss: 1.9972
X: 0.7999999999999936, Y: 10.399999999999988
Training Loss: 1.6386
X: 1.999999999999993, Y: 10.399999999999988
Training Loss: 1.7751
X: 3.199999999999992, Y: 10.399999999999988
Training Loss: 2.1694
X: 4.3999999999999915, Y: 10.399999999999988
Training Loss: 2.5885
X: 5.599999999999991, Y: 10.399999999999988
Training Loss: 3.0945
X: 6.79999999999999, Y: 10.399999999999988
Training Loss: 3.4518
X: 7.999999999999989, Y: 10.399999999999988
Training Loss: 4.2517
X: 9.199999999999989, Y: 10.399999999999988
Training Loss: 5.0308
X: 10.399999999999988, Y: 10.399999999999988
Training Loss: 6.6350
Saved to runs/12_epochs_from_-10_to_11_with_1.2ss-19_56_12_7_2022/new_data_VGG_PCA_pca.ply
training ResNet
epoch: 0
Train Loss: 0.4504, Train Acc: 0.17
Test Loss: 0.1973, Test Acc: 0.42
epoch: 1
Train Loss: 0.1535, Train Acc: 0.50
Test Loss: 0.1109, Test Acc: 0.63
epoch: 2
Train Loss: 0.1136, Train Acc: 0.62
Test Loss: 0.0844, Test Acc: 0.72
epoch: 3
Train Loss: 0.0889, Train Acc: 0.69
Test Loss: 0.0681, Test Acc: 0.78
epoch: 4
Train Loss: 0.0862, Train Acc: 0.71
Test Loss: 0.0585, Test Acc: 0.81
epoch: 5
Train Loss: 0.0692, Train Acc: 0.75
Test Loss: 0.0517, Test Acc: 0.83
epoch: 6
Train Loss: 0.0635, Train Acc: 0.80
Test Loss: 0.0493, Test Acc: 0.82
epoch: 7
Train Loss: 0.0511, Train Acc: 0.83
Test Loss: 0.0404, Test Acc: 0.86
epoch: 8
Train Loss: 0.0564, Train Acc: 0.82
Test Loss: 0.0383, Test Acc: 0.87
epoch: 9
Train Loss: 0.0543, Train Acc: 0.82
Test Loss: 0.0325, Test Acc: 0.90
epoch: 10
Train Loss: 0.0471, Train Acc: 0.85
Test Loss: 0.0318, Test Acc: 0.90
epoch: 11
Train Loss: 0.0464, Train Acc: 0.86
Test Loss: 0.0368, Test Acc: 0.88
X: -10.0, Y: -10.0
Training Loss: 3.6401
X: -8.8, Y: -10.0
Training Loss: 2.2514
X: -7.600000000000001, Y: -10.0
Training Loss: 1.4947
X: -6.400000000000002, Y: -10.0
Training Loss: 1.1811
X: -5.200000000000003, Y: -10.0
Training Loss: 0.9553
X: -4.0000000000000036, Y: -10.0
Training Loss: 0.8834
X: -2.8000000000000043, Y: -10.0
Training Loss: 0.7982
X: -1.600000000000005, Y: -10.0
Training Loss: 0.7934
X: -0.4000000000000057, Y: -10.0
Training Loss: 0.9739
X: 0.7999999999999936, Y: -10.0
Training Loss: 1.0608
X: 1.999999999999993, Y: -10.0
Training Loss: 1.0861
X: 3.199999999999992, Y: -10.0
Training Loss: 1.0729
X: 4.3999999999999915, Y: -10.0
Training Loss: 1.0376
X: 5.599999999999991, Y: -10.0
Training Loss: 0.8015
X: 6.79999999999999, Y: -10.0
Training Loss: 0.7300
X: 7.999999999999989, Y: -10.0
Training Loss: 0.7024
X: 9.199999999999989, Y: -10.0
Training Loss: 0.7929
X: 10.399999999999988, Y: -10.0
Training Loss: 0.8485
X: -10.0, Y: -8.8
Training Loss: 2.5610
X: -8.8, Y: -8.8
Training Loss: 1.5961
X: -7.600000000000001, Y: -8.8
Training Loss: 1.2027
X: -6.400000000000002, Y: -8.8
Training Loss: 1.0300
X: -5.200000000000003, Y: -8.8
Training Loss: 0.9791
X: -4.0000000000000036, Y: -8.8
Training Loss: 0.8670
X: -2.8000000000000043, Y: -8.8
Training Loss: 0.7647
X: -1.600000000000005, Y: -8.8
Training Loss: 0.7304
X: -0.4000000000000057, Y: -8.8
Training Loss: 0.7298
X: 0.7999999999999936, Y: -8.8
Training Loss: 0.7292
X: 1.999999999999993, Y: -8.8
Training Loss: 0.7592
X: 3.199999999999992, Y: -8.8
Training Loss: 0.7228
X: 4.3999999999999915, Y: -8.8
Training Loss: 0.6473
X: 5.599999999999991, Y: -8.8
Training Loss: 0.5460
X: 6.79999999999999, Y: -8.8
Training Loss: 0.5008
X: 7.999999999999989, Y: -8.8
Training Loss: 0.5015
X: 9.199999999999989, Y: -8.8
Training Loss: 0.6266
X: 10.399999999999988, Y: -8.8
Training Loss: 0.6712
X: -10.0, Y: -7.600000000000001
Training Loss: 1.9080
X: -8.8, Y: -7.600000000000001
Training Loss: 1.2947
X: -7.600000000000001, Y: -7.600000000000001
Training Loss: 1.0121
X: -6.400000000000002, Y: -7.600000000000001
Training Loss: 0.9421
X: -5.200000000000003, Y: -7.600000000000001
Training Loss: 0.8923
X: -4.0000000000000036, Y: -7.600000000000001
Training Loss: 0.8156
X: -2.8000000000000043, Y: -7.600000000000001
Training Loss: 0.6376
X: -1.600000000000005, Y: -7.600000000000001
Training Loss: 0.5514
X: -0.4000000000000057, Y: -7.600000000000001
Training Loss: 0.5230
X: 0.7999999999999936, Y: -7.600000000000001
Training Loss: 0.5225
X: 1.999999999999993, Y: -7.600000000000001
Training Loss: 0.4959
X: 3.199999999999992, Y: -7.600000000000001
Training Loss: 0.4964
X: 4.3999999999999915, Y: -7.600000000000001
Training Loss: 0.4518
X: 5.599999999999991, Y: -7.600000000000001
Training Loss: 0.4062
X: 6.79999999999999, Y: -7.600000000000001
Training Loss: 0.3950
X: 7.999999999999989, Y: -7.600000000000001
Training Loss: 0.4456
X: 9.199999999999989, Y: -7.600000000000001
Training Loss: 0.5592
X: 10.399999999999988, Y: -7.600000000000001
Training Loss: 0.5997
X: -10.0, Y: -6.400000000000002
Training Loss: 1.7323
X: -8.8, Y: -6.400000000000002
Training Loss: 1.1620
X: -7.600000000000001, Y: -6.400000000000002
Training Loss: 0.9523
X: -6.400000000000002, Y: -6.400000000000002
Training Loss: 0.8793
X: -5.200000000000003, Y: -6.400000000000002
Training Loss: 0.7691
X: -4.0000000000000036, Y: -6.400000000000002
Training Loss: 0.6367
X: -2.8000000000000043, Y: -6.400000000000002
Training Loss: 0.4943
X: -1.600000000000005, Y: -6.400000000000002
Training Loss: 0.4345
X: -0.4000000000000057, Y: -6.400000000000002
Training Loss: 0.3852
X: 0.7999999999999936, Y: -6.400000000000002
Training Loss: 0.3520
X: 1.999999999999993, Y: -6.400000000000002
Training Loss: 0.3553
X: 3.199999999999992, Y: -6.400000000000002
Training Loss: 0.3379
X: 4.3999999999999915, Y: -6.400000000000002
Training Loss: 0.3440
X: 5.599999999999991, Y: -6.400000000000002
Training Loss: 0.3277
X: 6.79999999999999, Y: -6.400000000000002
Training Loss: 0.3395
X: 7.999999999999989, Y: -6.400000000000002
Training Loss: 0.3934
X: 9.199999999999989, Y: -6.400000000000002
Training Loss: 0.4785
X: 10.399999999999988, Y: -6.400000000000002
Training Loss: 0.5515
X: -10.0, Y: -5.200000000000003
Training Loss: 1.5987
X: -8.8, Y: -5.200000000000003
Training Loss: 1.2246
X: -7.600000000000001, Y: -5.200000000000003
Training Loss: 1.0083
X: -6.400000000000002, Y: -5.200000000000003
Training Loss: 0.8541
X: -5.200000000000003, Y: -5.200000000000003
Training Loss: 0.6546
X: -4.0000000000000036, Y: -5.200000000000003
Training Loss: 0.4966
X: -2.8000000000000043, Y: -5.200000000000003
Training Loss: 0.3706
X: -1.600000000000005, Y: -5.200000000000003
Training Loss: 0.3159
X: -0.4000000000000057, Y: -5.200000000000003
Training Loss: 0.2649
X: 0.7999999999999936, Y: -5.200000000000003
Training Loss: 0.2473
X: 1.999999999999993, Y: -5.200000000000003
Training Loss: 0.2644
X: 3.199999999999992, Y: -5.200000000000003
Training Loss: 0.2654
X: 4.3999999999999915, Y: -5.200000000000003
Training Loss: 0.2825
X: 5.599999999999991, Y: -5.200000000000003
Training Loss: 0.2923
X: 6.79999999999999, Y: -5.200000000000003
Training Loss: 0.3162
X: 7.999999999999989, Y: -5.200000000000003
Training Loss: 0.3905
X: 9.199999999999989, Y: -5.200000000000003
Training Loss: 0.4888
X: 10.399999999999988, Y: -5.200000000000003
Training Loss: 0.5156
X: -10.0, Y: -4.0000000000000036
Training Loss: 1.7163
X: -8.8, Y: -4.0000000000000036
Training Loss: 1.3915
X: -7.600000000000001, Y: -4.0000000000000036
Training Loss: 1.0831
X: -6.400000000000002, Y: -4.0000000000000036
Training Loss: 0.8208
X: -5.200000000000003, Y: -4.0000000000000036
Training Loss: 0.6102
X: -4.0000000000000036, Y: -4.0000000000000036
Training Loss: 0.4278
X: -2.8000000000000043, Y: -4.0000000000000036
Training Loss: 0.2993
X: -1.600000000000005, Y: -4.0000000000000036
Training Loss: 0.2259
X: -0.4000000000000057, Y: -4.0000000000000036
Training Loss: 0.1652
X: 0.7999999999999936, Y: -4.0000000000000036
Training Loss: 0.1701
X: 1.999999999999993, Y: -4.0000000000000036
Training Loss: 0.1708
X: 3.199999999999992, Y: -4.0000000000000036
Training Loss: 0.1912
X: 4.3999999999999915, Y: -4.0000000000000036
Training Loss: 0.2330
X: 5.599999999999991, Y: -4.0000000000000036
Training Loss: 0.2604
X: 6.79999999999999, Y: -4.0000000000000036
Training Loss: 0.3112
X: 7.999999999999989, Y: -4.0000000000000036
Training Loss: 0.3967
X: 9.199999999999989, Y: -4.0000000000000036
Training Loss: 0.4720
X: 10.399999999999988, Y: -4.0000000000000036
Training Loss: 0.5685
X: -10.0, Y: -2.8000000000000043
Training Loss: 1.7809
X: -8.8, Y: -2.8000000000000043
Training Loss: 1.4073
X: -7.600000000000001, Y: -2.8000000000000043
Training Loss: 1.1235
X: -6.400000000000002, Y: -2.8000000000000043
Training Loss: 0.7495
X: -5.200000000000003, Y: -2.8000000000000043
Training Loss: 0.4866
X: -4.0000000000000036, Y: -2.8000000000000043
Training Loss: 0.3302
X: -2.8000000000000043, Y: -2.8000000000000043
Training Loss: 0.2109
X: -1.600000000000005, Y: -2.8000000000000043
Training Loss: 0.1506
X: -0.4000000000000057, Y: -2.8000000000000043
Training Loss: 0.1169
X: 0.7999999999999936, Y: -2.8000000000000043
Training Loss: 0.0930
X: 1.999999999999993, Y: -2.8000000000000043
Training Loss: 0.1174
X: 3.199999999999992, Y: -2.8000000000000043
Training Loss: 0.1348
X: 4.3999999999999915, Y: -2.8000000000000043
Training Loss: 0.1808
X: 5.599999999999991, Y: -2.8000000000000043
Training Loss: 0.2444
X: 6.79999999999999, Y: -2.8000000000000043
Training Loss: 0.3255
X: 7.999999999999989, Y: -2.8000000000000043
Training Loss: 0.4157
X: 9.199999999999989, Y: -2.8000000000000043
Training Loss: 0.4862
X: 10.399999999999988, Y: -2.8000000000000043
Training Loss: 0.5733
X: -10.0, Y: -1.600000000000005
Training Loss: 1.8570
X: -8.8, Y: -1.600000000000005
Training Loss: 1.3494
X: -7.600000000000001, Y: -1.600000000000005
Training Loss: 0.9410
X: -6.400000000000002, Y: -1.600000000000005
Training Loss: 0.6141
X: -5.200000000000003, Y: -1.600000000000005
Training Loss: 0.3638
X: -4.0000000000000036, Y: -1.600000000000005
Training Loss: 0.2114
X: -2.8000000000000043, Y: -1.600000000000005
Training Loss: 0.1318
X: -1.600000000000005, Y: -1.600000000000005
Training Loss: 0.0884
X: -0.4000000000000057, Y: -1.600000000000005
Training Loss: 0.0595
X: 0.7999999999999936, Y: -1.600000000000005
Training Loss: 0.0553
X: 1.999999999999993, Y: -1.600000000000005
Training Loss: 0.0758
X: 3.199999999999992, Y: -1.600000000000005
Training Loss: 0.1173
X: 4.3999999999999915, Y: -1.600000000000005
Training Loss: 0.1757
X: 5.599999999999991, Y: -1.600000000000005
Training Loss: 0.2538
X: 6.79999999999999, Y: -1.600000000000005
Training Loss: 0.3657
X: 7.999999999999989, Y: -1.600000000000005
Training Loss: 0.4641
X: 9.199999999999989, Y: -1.600000000000005
Training Loss: 0.5364
X: 10.399999999999988, Y: -1.600000000000005
Training Loss: 0.5872
X: -10.0, Y: -0.4000000000000057
Training Loss: 1.5914
X: -8.8, Y: -0.4000000000000057
Training Loss: 1.1630
X: -7.600000000000001, Y: -0.4000000000000057
Training Loss: 0.7932
X: -6.400000000000002, Y: -0.4000000000000057
Training Loss: 0.4934
X: -5.200000000000003, Y: -0.4000000000000057
Training Loss: 0.2754
X: -4.0000000000000036, Y: -0.4000000000000057
Training Loss: 0.1402
X: -2.8000000000000043, Y: -0.4000000000000057
Training Loss: 0.0738
X: -1.600000000000005, Y: -0.4000000000000057
Training Loss: 0.0472
X: -0.4000000000000057, Y: -0.4000000000000057
Training Loss: 0.0319
X: 0.7999999999999936, Y: -0.4000000000000057
Training Loss: 0.0376
X: 1.999999999999993, Y: -0.4000000000000057
Training Loss: 0.0651
X: 3.199999999999992, Y: -0.4000000000000057
Training Loss: 0.1184
X: 4.3999999999999915, Y: -0.4000000000000057
Training Loss: 0.1931
X: 5.599999999999991, Y: -0.4000000000000057
Training Loss: 0.3031
X: 6.79999999999999, Y: -0.4000000000000057
Training Loss: 0.4170
X: 7.999999999999989, Y: -0.4000000000000057
Training Loss: 0.4917
X: 9.199999999999989, Y: -0.4000000000000057
Training Loss: 0.5525
X: 10.399999999999988, Y: -0.4000000000000057
Training Loss: 0.6102
X: -10.0, Y: 0.7999999999999936
Training Loss: 1.3628
X: -8.8, Y: 0.7999999999999936
Training Loss: 1.0795
X: -7.600000000000001, Y: 0.7999999999999936
Training Loss: 0.7247
X: -6.400000000000002, Y: 0.7999999999999936
Training Loss: 0.4171
X: -5.200000000000003, Y: 0.7999999999999936
Training Loss: 0.2471
X: -4.0000000000000036, Y: 0.7999999999999936
Training Loss: 0.1179
X: -2.8000000000000043, Y: 0.7999999999999936
Training Loss: 0.0601
X: -1.600000000000005, Y: 0.7999999999999936
Training Loss: 0.0426
X: -0.4000000000000057, Y: 0.7999999999999936
Training Loss: 0.0342
X: 0.7999999999999936, Y: 0.7999999999999936
Training Loss: 0.0476
X: 1.999999999999993, Y: 0.7999999999999936
Training Loss: 0.0823
X: 3.199999999999992, Y: 0.7999999999999936
Training Loss: 0.1500
X: 4.3999999999999915, Y: 0.7999999999999936
Training Loss: 0.2546
X: 5.599999999999991, Y: 0.7999999999999936
Training Loss: 0.3550
X: 6.79999999999999, Y: 0.7999999999999936
Training Loss: 0.4547
X: 7.999999999999989, Y: 0.7999999999999936
Training Loss: 0.5115
X: 9.199999999999989, Y: 0.7999999999999936
Training Loss: 0.5490
X: 10.399999999999988, Y: 0.7999999999999936
Training Loss: 0.6000
X: -10.0, Y: 1.999999999999993
Training Loss: 1.2598
X: -8.8, Y: 1.999999999999993
Training Loss: 0.9019
X: -7.600000000000001, Y: 1.999999999999993
Training Loss: 0.6279
X: -6.400000000000002, Y: 1.999999999999993
Training Loss: 0.3878
X: -5.200000000000003, Y: 1.999999999999993
Training Loss: 0.2295
X: -4.0000000000000036, Y: 1.999999999999993
Training Loss: 0.1424
X: -2.8000000000000043, Y: 1.999999999999993
Training Loss: 0.0856
X: -1.600000000000005, Y: 1.999999999999993
Training Loss: 0.0662
X: -0.4000000000000057, Y: 1.999999999999993
Training Loss: 0.0726
X: 0.7999999999999936, Y: 1.999999999999993
Training Loss: 0.0936
X: 1.999999999999993, Y: 1.999999999999993
Training Loss: 0.1454
X: 3.199999999999992, Y: 1.999999999999993
Training Loss: 0.2185
X: 4.3999999999999915, Y: 1.999999999999993
Training Loss: 0.3188
X: 5.599999999999991, Y: 1.999999999999993
Training Loss: 0.4187
X: 6.79999999999999, Y: 1.999999999999993
Training Loss: 0.4826
X: 7.999999999999989, Y: 1.999999999999993
Training Loss: 0.5313
X: 9.199999999999989, Y: 1.999999999999993
Training Loss: 0.5666
X: 10.399999999999988, Y: 1.999999999999993
Training Loss: 0.6122
X: -10.0, Y: 3.199999999999992
Training Loss: 1.1967
X: -8.8, Y: 3.199999999999992
Training Loss: 0.8945
X: -7.600000000000001, Y: 3.199999999999992
Training Loss: 0.6125
X: -6.400000000000002, Y: 3.199999999999992
Training Loss: 0.3826
X: -5.200000000000003, Y: 3.199999999999992
Training Loss: 0.2522
X: -4.0000000000000036, Y: 3.199999999999992
Training Loss: 0.1716
X: -2.8000000000000043, Y: 3.199999999999992
Training Loss: 0.1315
X: -1.600000000000005, Y: 3.199999999999992
Training Loss: 0.1178
X: -0.4000000000000057, Y: 3.199999999999992
Training Loss: 0.1336
X: 0.7999999999999936, Y: 3.199999999999992
Training Loss: 0.1686
X: 1.999999999999993, Y: 3.199999999999992
Training Loss: 0.2296
X: 3.199999999999992, Y: 3.199999999999992
Training Loss: 0.3224
X: 4.3999999999999915, Y: 3.199999999999992
Training Loss: 0.4105
X: 5.599999999999991, Y: 3.199999999999992
Training Loss: 0.4906
X: 6.79999999999999, Y: 3.199999999999992
Training Loss: 0.5397
X: 7.999999999999989, Y: 3.199999999999992
Training Loss: 0.5741
X: 9.199999999999989, Y: 3.199999999999992
Training Loss: 0.6023
X: 10.399999999999988, Y: 3.199999999999992
Training Loss: 0.6299
X: -10.0, Y: 4.3999999999999915
Training Loss: 1.2384
X: -8.8, Y: 4.3999999999999915
Training Loss: 0.8611
X: -7.600000000000001, Y: 4.3999999999999915
Training Loss: 0.5689
X: -6.400000000000002, Y: 4.3999999999999915
Training Loss: 0.3849
X: -5.200000000000003, Y: 4.3999999999999915
Training Loss: 0.2685
X: -4.0000000000000036, Y: 4.3999999999999915
Training Loss: 0.2080
X: -2.8000000000000043, Y: 4.3999999999999915
Training Loss: 0.1918
X: -1.600000000000005, Y: 4.3999999999999915
Training Loss: 0.1907
X: -0.4000000000000057, Y: 4.3999999999999915
Training Loss: 0.2153
X: 0.7999999999999936, Y: 4.3999999999999915
Training Loss: 0.2529
X: 1.999999999999993, Y: 4.3999999999999915
Training Loss: 0.3216
X: 3.199999999999992, Y: 4.3999999999999915
Training Loss: 0.4097
X: 4.3999999999999915, Y: 4.3999999999999915
Training Loss: 0.4969
X: 5.599999999999991, Y: 4.3999999999999915
Training Loss: 0.5580
X: 6.79999999999999, Y: 4.3999999999999915
Training Loss: 0.5956
X: 7.999999999999989, Y: 4.3999999999999915
Training Loss: 0.6194
X: 9.199999999999989, Y: 4.3999999999999915
Training Loss: 0.6367
X: 10.399999999999988, Y: 4.3999999999999915
Training Loss: 0.6576
X: -10.0, Y: 5.599999999999991
Training Loss: 1.2585
X: -8.8, Y: 5.599999999999991
Training Loss: 0.8212
X: -7.600000000000001, Y: 5.599999999999991
Training Loss: 0.5038
X: -6.400000000000002, Y: 5.599999999999991
Training Loss: 0.3563
X: -5.200000000000003, Y: 5.599999999999991
Training Loss: 0.2786
X: -4.0000000000000036, Y: 5.599999999999991
Training Loss: 0.2591
X: -2.8000000000000043, Y: 5.599999999999991
Training Loss: 0.2495
X: -1.600000000000005, Y: 5.599999999999991
Training Loss: 0.2631
X: -0.4000000000000057, Y: 5.599999999999991
Training Loss: 0.2721
X: 0.7999999999999936, Y: 5.599999999999991
Training Loss: 0.3216
X: 1.999999999999993, Y: 5.599999999999991
Training Loss: 0.4003
X: 3.199999999999992, Y: 5.599999999999991
Training Loss: 0.4816
X: 4.3999999999999915, Y: 5.599999999999991
Training Loss: 0.5532
X: 5.599999999999991, Y: 5.599999999999991
Training Loss: 0.6022
X: 6.79999999999999, Y: 5.599999999999991
Training Loss: 0.6311
X: 7.999999999999989, Y: 5.599999999999991
Training Loss: 0.6541
X: 9.199999999999989, Y: 5.599999999999991
Training Loss: 0.6688
X: 10.399999999999988, Y: 5.599999999999991
Training Loss: 0.6837
X: -10.0, Y: 6.79999999999999
Training Loss: 1.2009
X: -8.8, Y: 6.79999999999999
Training Loss: 0.7004
X: -7.600000000000001, Y: 6.79999999999999
Training Loss: 0.5060
X: -6.400000000000002, Y: 6.79999999999999
Training Loss: 0.3695
X: -5.200000000000003, Y: 6.79999999999999
Training Loss: 0.3329
X: -4.0000000000000036, Y: 6.79999999999999
Training Loss: 0.3139
X: -2.8000000000000043, Y: 6.79999999999999
Training Loss: 0.2994
X: -1.600000000000005, Y: 6.79999999999999
Training Loss: 0.2994
X: -0.4000000000000057, Y: 6.79999999999999
Training Loss: 0.3288
X: 0.7999999999999936, Y: 6.79999999999999
Training Loss: 0.3808
X: 1.999999999999993, Y: 6.79999999999999
Training Loss: 0.4505
X: 3.199999999999992, Y: 6.79999999999999
Training Loss: 0.5166
X: 4.3999999999999915, Y: 6.79999999999999
Training Loss: 0.5800
X: 5.599999999999991, Y: 6.79999999999999
Training Loss: 0.6251
X: 6.79999999999999, Y: 6.79999999999999
Training Loss: 0.6595
X: 7.999999999999989, Y: 6.79999999999999
Training Loss: 0.6778
X: 9.199999999999989, Y: 6.79999999999999
Training Loss: 0.6863
X: 10.399999999999988, Y: 6.79999999999999
Training Loss: 0.6943
X: -10.0, Y: 7.999999999999989
Training Loss: 1.0597
X: -8.8, Y: 7.999999999999989
Training Loss: 0.6543
X: -7.600000000000001, Y: 7.999999999999989
Training Loss: 0.4556
X: -6.400000000000002, Y: 7.999999999999989
Training Loss: 0.3994
X: -5.200000000000003, Y: 7.999999999999989
Training Loss: 0.3734
X: -4.0000000000000036, Y: 7.999999999999989
Training Loss: 0.3526
X: -2.8000000000000043, Y: 7.999999999999989
Training Loss: 0.3321
X: -1.600000000000005, Y: 7.999999999999989
Training Loss: 0.3372
X: -0.4000000000000057, Y: 7.999999999999989
Training Loss: 0.3662
X: 0.7999999999999936, Y: 7.999999999999989
Training Loss: 0.4284
X: 1.999999999999993, Y: 7.999999999999989
Training Loss: 0.4971
X: 3.199999999999992, Y: 7.999999999999989
Training Loss: 0.5519
X: 4.3999999999999915, Y: 7.999999999999989
Training Loss: 0.6014
X: 5.599999999999991, Y: 7.999999999999989
Training Loss: 0.6394
X: 6.79999999999999, Y: 7.999999999999989
Training Loss: 0.6643
X: 7.999999999999989, Y: 7.999999999999989
Training Loss: 0.6862
X: 9.199999999999989, Y: 7.999999999999989
Training Loss: 0.7021
X: 10.399999999999988, Y: 7.999999999999989
Training Loss: 0.7064
X: -10.0, Y: 9.199999999999989
Training Loss: 1.0139
X: -8.8, Y: 9.199999999999989
Training Loss: 0.6311
X: -7.600000000000001, Y: 9.199999999999989
Training Loss: 0.5051
X: -6.400000000000002, Y: 9.199999999999989
Training Loss: 0.4285
X: -5.200000000000003, Y: 9.199999999999989
Training Loss: 0.4118
X: -4.0000000000000036, Y: 9.199999999999989
Training Loss: 0.3843
X: -2.8000000000000043, Y: 9.199999999999989
Training Loss: 0.3624
X: -1.600000000000005, Y: 9.199999999999989
Training Loss: 0.3674
X: -0.4000000000000057, Y: 9.199999999999989
Training Loss: 0.4156
X: 0.7999999999999936, Y: 9.199999999999989
Training Loss: 0.4700
X: 1.999999999999993, Y: 9.199999999999989
Training Loss: 0.5279
X: 3.199999999999992, Y: 9.199999999999989
Training Loss: 0.5774
X: 4.3999999999999915, Y: 9.199999999999989
Training Loss: 0.6159
X: 5.599999999999991, Y: 9.199999999999989
Training Loss: 0.6528
X: 6.79999999999999, Y: 9.199999999999989
Training Loss: 0.6708
X: 7.999999999999989, Y: 9.199999999999989
Training Loss: 0.6866
X: 9.199999999999989, Y: 9.199999999999989
Training Loss: 0.7040
X: 10.399999999999988, Y: 9.199999999999989
Training Loss: 0.7126
X: -10.0, Y: 10.399999999999988
Training Loss: 0.9508
X: -8.8, Y: 10.399999999999988
Training Loss: 0.6543
X: -7.600000000000001, Y: 10.399999999999988
Training Loss: 0.5000
X: -6.400000000000002, Y: 10.399999999999988
Training Loss: 0.4692
X: -5.200000000000003, Y: 10.399999999999988
Training Loss: 0.4477
X: -4.0000000000000036, Y: 10.399999999999988
Training Loss: 0.4199
X: -2.8000000000000043, Y: 10.399999999999988
Training Loss: 0.3947
X: -1.600000000000005, Y: 10.399999999999988
Training Loss: 0.4104
X: -0.4000000000000057, Y: 10.399999999999988
Training Loss: 0.4319
X: 0.7999999999999936, Y: 10.399999999999988
Training Loss: 0.4957
X: 1.999999999999993, Y: 10.399999999999988
Training Loss: 0.5531
X: 3.199999999999992, Y: 10.399999999999988
Training Loss: 0.6062
X: 4.3999999999999915, Y: 10.399999999999988
Training Loss: 0.6354
X: 5.599999999999991, Y: 10.399999999999988
Training Loss: 0.6600
X: 6.79999999999999, Y: 10.399999999999988
Training Loss: 0.6852
X: 7.999999999999989, Y: 10.399999999999988
Training Loss: 0.6953
X: 9.199999999999989, Y: 10.399999999999988
Training Loss: 0.7052
X: 10.399999999999988, Y: 10.399999999999988
Training Loss: 0.7160
Saved to runs/12_epochs_from_-10_to_11_with_1.2ss-19_56_12_7_2022/new_data_ResNet_PCA_pca.ply
