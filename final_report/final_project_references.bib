
@inproceedings{NEURIPS2018_a41b3bb3,
 author = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Visualizing the Loss Landscape of Neural Nets},
 url = {https://proceedings.neurips.cc/paper/2018/file/a41b3bb3e6b050b6c9067c67f663b915-Paper.pdf},
 volume = {31},
 year = {2018}
}

@article{hochreiter1997flat,
  title={Flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={1},
  pages={1--42},
  year={1997},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{ABIODUN2018e00938,
title = {State-of-the-art in artificial neural network applications: A survey},
journal = {Heliyon},
volume = {4},
number = {11},
pages = {e00938},
year = {2018},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2018.e00938},
url = {https://www.sciencedirect.com/science/article/pii/S2405844018332067},
author = {Oludare Isaac Abiodun and Aman Jantan and Abiodun Esther Omolara and Kemi Victoria Dada and Nachaat AbdElatif Mohamed and Humaira Arshad},
keywords = {Computer science},
abstract = {This is a survey of neural network applications in the real-world scenario. It provides a taxonomy of artificial neural networks (ANNs) and furnish the reader with knowledge of current and emerging trends in ANN applications research and area of focus for researchers. Additionally, the study presents ANN application challenges, contributions, compare performances and critiques methods. The study covers many applications of ANN techniques in various disciplines which include computing, science, engineering, medicine, environmental, agriculture, mining, technology, climate, business, arts, and nanotechnology, etc. The study assesses ANN contributions, compare performances and critiques methods. The study found that neural-network models such as feedforward and feedback propagation artificial neural networks are performing better in its application to human problems. Therefore, we proposed feedforward and feedback propagation ANN models for research focus based on data analysis factors like accuracy, processing speed, latency, fault tolerance, volume, scalability, convergence, and performance. Moreover, we recommend that instead of applying a single method, future research can focus on combining ANN models into one network-wide application.}
}

@InProceedings{pmlr-v137-huang20a,
  title = 	 {Understanding Generalization Through Visualizations},
  author =       {Huang, W. Ronny and Emam, Zeyad and Goldblum, Micah and Fowl, Liam and Terry, Justin K. and Huang, Furong and Goldstein, Tom},
  booktitle = 	 {Proceedings on "I Can't Believe It's Not Better!" at NeurIPS Workshops},
  pages = 	 {87--97},
  year = 	 {2020},
  editor = 	 {Zosa Forde, Jessica and Ruiz, Francisco and Pradier, Melanie F. and Schein, Aaron},
  volume = 	 {137},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v137/huang20a/huang20a.pdf},
  url = 	 {https://proceedings.mlr.press/v137/huang20a.html},
  abstract = 	 {The power of neural networks lies in their ability to generalize to unseen data, yet the underlying reasons for this phenomenon remain elusive. Numerous rigorous attempts have been made to explain generalization, but available bounds are still quite loose, and analysis does not always lead to true understanding. The goal of this work is to make generalization more intuitive. Using visualization methods, we discuss the mystery of generalization, the geometry of loss landscapes, and how the curse (or, rather, the blessing) of dimensionality causes optimizers to settle into minima that generalize well.}
}

@article{linse2022walk,
  title={A walk in the black-box: 3D visualization of large neural networks in virtual reality},
  author={Linse, Christoph and Alshazly, Hammam and Martinetz, Thomas},
  journal={Neural Computing and Applications},
  pages={1--16},
  year={2022},
  publisher={Springer}
}

@misc{actor2020,
  doi = {10.48550/ARXIV.2009.02391},
  url = {https://arxiv.org/abs/2009.02391},
  author = {Bekci, Recep Yusuf and Gümüş, Mehmet},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Visualizing the Loss Landscape of Actor Critic Methods with Applications in Inventory Optimization},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{plaat2022deep,
  title={Deep Reinforcement Learning},
  author={Plaat, Aske},
  journal={arXiv preprint arXiv:2201.02135},
  year={2022}
}

@misc{https://doi.org/10.48550/arxiv.1511.08458,
  doi = {10.48550/ARXIV.1511.08458},
  
  url = {https://arxiv.org/abs/1511.08458},
  
  author = {O'Shea, Keiron and Nash, Ryan},
  
  keywords = {Neural and Evolutionary Computing (cs.NE), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {An Introduction to Convolutional Neural Networks},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1512.03385,
  doi = {10.48550/ARXIV.1512.03385},
  
  url = {https://arxiv.org/abs/1512.03385},
  
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Deep Residual Learning for Image Recognition},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}